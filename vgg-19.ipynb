{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["H2zoWFyt9znL"]},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Material Recognition using Transfer Learning on VGG19\n\nThe goal of this project is to train a convolutional neural network to classify color photographs of surfaces into one of ten common material categories: fabric, foliage, glass, leather, metal, paper, plastic, stone, water, and wood. Some tasks to consider:\n\n1. Modify some previously published architectures e.g., increase the network depth, reducing their parameters, etc.\n2. Try data augmentation to increase the number of training images\n3. Try a larger dataset, Materials in Context Database (MINC)\n\nDataset: Flickr Material Database (FMD)","metadata":{"id":"4uYqCzjRtWzk"}},{"cell_type":"markdown","source":"The notebook here will focus on transfer learning using VGG-19. The overview of this notebook is as follows:\n\n1. Preprocessing\n\n2. Train-Val-Test split\n\n3. Defining base model architecture using VGG-19\n\n4. Transfer Learning on VGG-19 with Adam Optimiser (all frozen layers), hyperparameter tuning it using Keras-Tuner, evaluation on test dataset\n\n5. Transfer Learning on VGG-19 with SGD Optimiser (all frozen layers) and hyperparameter tuning it using Keras-Tuner, evaluation on test dataset\n\n6. Transfer Learning on VGG-19 with Adam Optimiser (with some unfrozen layers), hyperparameter tuning it using Keras-Tuner, evaluation on test dataset\n\n7. Transfer Learning on VGG-19 with SGD Optimiser (with some unfrozen layers) and hyperparameter tuning it using Keras-Tuner, evaluation on test dataset\n\n8. New Train-Val_Test split after addition of images generated using GAN\n\n9. Transfer Learning on VGG-19 with Adam Optimiser with GAN (all frozen layers), hyperparameter tuning it using Keras-Tuner, evaluation on test dataset\n\n10. Transfer Learning on VGG-19 with SGD Optimiser with GAN (all frozen layers) and hyperparameter tuning it using Keras-Tuner, evaluation on test dataset\n\n11. Transfer Learning on VGG-19 with Adam Optimiser with GAN (with some unfrozen layers), hyperparameter tuning it using Keras-Tuner, evaluation on test dataset\n\n12. Transfer Learning on VGG-19 with SGD Optimiser with GAN(with some unfrozen layers) and hyperparameter tuning it using Keras-Tuner, evaluation on test dataset\n","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"id":"Ux_-dUsJtWzp"}},{"cell_type":"code","source":"import keras_tuner as kt\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras import Sequential","metadata":{"id":"jNpxoD3CtWzq","execution":{"iopub.status.busy":"2022-11-11T07:23:26.561007Z","iopub.execute_input":"2022-11-11T07:23:26.561360Z","iopub.status.idle":"2022-11-11T07:23:32.269272Z","shell.execute_reply.started":"2022-11-11T07:23:26.561330Z","shell.execute_reply":"2022-11-11T07:23:32.268242Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Train-validation-test split ","metadata":{}},{"cell_type":"code","source":"materials = ['fabric','foliage','glass','leather','metal','paper','plastic','stone','water','wood']\n\npath_to_folder = '../input/fmdmaterials/image'\ndef train_val_dataset(validation_split, seed):\n    \n    train_dataset = tf.keras.utils.image_dataset_from_directory(\n    directory=path_to_folder,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=materials,\n    # color_mode='grayscale',\n    batch_size=32,\n    image_size=(224,224),\n    shuffle=True,\n    seed=seed,\n    validation_split=validation_split,\n    subset='training')\n    \n    \n    validation_dataset = tf.keras.utils.image_dataset_from_directory(\n    directory=path_to_folder,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=materials,\n    # color_mode='grayscale',\n    batch_size=32,\n    image_size=(224,224),\n    shuffle=True,\n    seed=seed,\n    validation_split=validation_split,\n    subset='validation'\n)\n    \n    return train_dataset, validation_dataset\n    \n    \n    ","metadata":{"id":"kt4yi0ljtWzs","execution":{"iopub.status.busy":"2022-11-10T21:04:17.154087Z","iopub.execute_input":"2022-11-10T21:04:17.155305Z","iopub.status.idle":"2022-11-10T21:04:17.163245Z","shell.execute_reply.started":"2022-11-10T21:04:17.155267Z","shell.execute_reply":"2022-11-10T21:04:17.162214Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"test_dataset = tf.keras.utils.image_dataset_from_directory(\n    directory='../input/testmaterial/test/data/test',\n    labels='inferred',\n    label_mode='categorical',\n    class_names=materials,\n    # color_mode='grayscale',\n    batch_size=32,\n    image_size=(224,224),\n    shuffle=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lzE5yZtp_XH7","outputId":"6043e8d1-bf89-45df-dc30-f98b144e3551","execution":{"iopub.status.busy":"2022-11-11T08:06:28.955068Z","iopub.execute_input":"2022-11-11T08:06:28.955477Z","iopub.status.idle":"2022-11-11T08:06:29.091425Z","shell.execute_reply.started":"2022-11-11T08:06:28.955442Z","shell.execute_reply":"2022-11-11T08:06:29.089787Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Found 30 files belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset, validation_dataset= train_val_dataset(0.3, 42)","metadata":{"scrolled":true,"id":"JPLNDeoWtWzt","outputId":"0f103b3d-a157-455a-c69f-aaeadf3a63d4","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2022-11-10T21:04:20.004950Z","iopub.execute_input":"2022-11-10T21:04:20.005363Z","iopub.status.idle":"2022-11-10T21:04:23.434956Z","shell.execute_reply.started":"2022-11-10T21:04:20.005328Z","shell.execute_reply":"2022-11-10T21:04:23.433838Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 1000 files belonging to 10 classes.\nUsing 700 files for training.\nFound 1000 files belonging to 10 classes.\nUsing 300 files for validation.\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 21:04:20.396253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-10 21:04:20.574121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-10 21:04:20.575074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-10 21:04:20.578519: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-10 21:04:20.578911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-10 21:04:20.579931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-10 21:04:20.580636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-10 21:04:22.861213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-10 21:04:22.862068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-10 21:04:22.862876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-10 21:04:22.863529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data augmentation","metadata":{"id":"7118PfWLtWzu"}},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.RandomFlip(\"vertical\"),\n  tf.keras.layers.RandomRotation(0.2),\n])","metadata":{"id":"fXly32DptWzu","execution":{"iopub.status.busy":"2022-11-11T07:33:23.816231Z","iopub.execute_input":"2022-11-11T07:33:23.817331Z","iopub.status.idle":"2022-11-11T07:33:23.831589Z","shell.execute_reply.started":"2022-11-11T07:33:23.817285Z","shell.execute_reply":"2022-11-11T07:33:23.830411Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Using pre-trained VGG19 as base model","metadata":{}},{"cell_type":"code","source":"image_shape = (224,224) + (3,)\nbase_model = tf.keras.applications.vgg19.VGG19(input_shape=image_shape,\n                                               include_top=False,\n                                               weights='imagenet')","metadata":{"id":"e8YORF6itWzv","execution":{"iopub.status.busy":"2022-11-11T07:24:29.235965Z","iopub.execute_input":"2022-11-11T07:24:29.236340Z","iopub.status.idle":"2022-11-11T07:24:30.000091Z","shell.execute_reply.started":"2022-11-11T07:24:29.236308Z","shell.execute_reply":"2022-11-11T07:24:29.999033Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80142336/80134624 [==============================] - 0s 0us/step\n80150528/80134624 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"preprocess_input = tf.keras.applications.vgg19.preprocess_input","metadata":{"id":"h9ZcpQgstWzw","execution":{"iopub.status.busy":"2022-11-11T07:24:32.764588Z","iopub.execute_input":"2022-11-11T07:24:32.764969Z","iopub.status.idle":"2022-11-11T07:24:32.770391Z","shell.execute_reply.started":"2022-11-11T07:24:32.764919Z","shell.execute_reply":"2022-11-11T07:24:32.768981Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-11T07:24:33.951246Z","iopub.execute_input":"2022-11-11T07:24:33.951955Z","iopub.status.idle":"2022-11-11T07:24:33.960766Z","shell.execute_reply.started":"2022-11-11T07:24:33.951903Z","shell.execute_reply":"2022-11-11T07:24:33.959653Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"vgg19\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n=================================================================\nTotal params: 20,024,384\nTrainable params: 20,024,384\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Transfer Learning and tune the hyperparameters with frozen layers (Adam optimizer)","metadata":{"id":"e9IQaDCItWzz"}},{"cell_type":"code","source":"base_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-11-10T21:23:29.867815Z","iopub.execute_input":"2022-11-10T21:23:29.868228Z","iopub.status.idle":"2022-11-10T21:23:29.873931Z","shell.execute_reply.started":"2022-11-10T21:23:29.868172Z","shell.execute_reply":"2022-11-10T21:23:29.872583Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def model_builder(hp):\n    \n    hp_units = hp.Choice('units', [16, 32, 64, 128, 256, 512, 1024])\n    hp_lr = hp.Choice('lr', [1e-2, 1e-3, 1e-4])\n    hp_ratio1 = hp.Choice('ratio1', [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])\n    hp_ratio2 = hp.Choice('ratio2', [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])\n    hp_activation = hp.Choice('activation', ['relu', 'elu'])\n        \n    inputs = tf.keras.Input(shape=(224, 224, 3))\n    \n    x = data_augmentation(inputs)\n    x = preprocess_input(x)\n    x = base_model(x, training=False)\n    x = Flatten()(x)\n    x = Dropout(hp_ratio1)(x)\n    x = Dense(units=hp_units, activation=hp_activation)(x)\n    x = Dropout(hp_ratio2)(x)\n    prediction = Dense(10, activation='softmax')(x)\n    model = tf.keras.Model(inputs=inputs, outputs=prediction)\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=hp_lr),\n        loss=tf.keras.losses.CategoricalCrossentropy(),\n        metrics=['accuracy']\n    )\n\n    return model","metadata":{"id":"RXPLKC73tWzz","execution":{"iopub.status.busy":"2022-11-11T07:31:52.614334Z","iopub.execute_input":"2022-11-11T07:31:52.614938Z","iopub.status.idle":"2022-11-11T07:31:52.625678Z","shell.execute_reply.started":"2022-11-11T07:31:52.614903Z","shell.execute_reply":"2022-11-11T07:31:52.624541Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tuner = kt.Hyperband(\n    model_builder,\n    objective='val_accuracy',\n    max_epochs=10,\n    directory=\"./\",\n)","metadata":{"scrolled":true,"id":"QP9n8g1itWzz","execution":{"iopub.status.busy":"2022-11-10T21:24:47.794028Z","iopub.execute_input":"2022-11-10T21:24:47.794714Z","iopub.status.idle":"2022-11-10T21:24:48.035027Z","shell.execute_reply.started":"2022-11-10T21:24:47.794674Z","shell.execute_reply":"2022-11-10T21:24:48.033908Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)","metadata":{"id":"0zXsb64wtWz0","execution":{"iopub.status.busy":"2022-11-10T21:24:51.217883Z","iopub.execute_input":"2022-11-10T21:24:51.218293Z","iopub.status.idle":"2022-11-10T21:24:51.223600Z","shell.execute_reply.started":"2022-11-10T21:24:51.218256Z","shell.execute_reply":"2022-11-10T21:24:51.222426Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"tuner.search(train_dataset, epochs=50,validation_data=validation_dataset, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]","metadata":{"scrolled":true,"id":"r_SZKjOftWz0","outputId":"87d0a6a0-c23c-4049-a566-b7dd70705374","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2022-11-10T21:24:54.729265Z","iopub.execute_input":"2022-11-10T21:24:54.729649Z","iopub.status.idle":"2022-11-10T21:35:41.324562Z","shell.execute_reply.started":"2022-11-10T21:24:54.729616Z","shell.execute_reply":"2022-11-10T21:35:41.321495Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Trial 30 Complete [00h 00m 47s]\nval_accuracy: 0.11666666716337204\n\nBest val_accuracy So Far: 0.7599999904632568\nTotal elapsed time: 00h 10m 46s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(best_hps.get('units'))\nprint(best_hps.get('lr'))\nprint(best_hps.get('ratio1'))\nprint(best_hps.get('ratio2'))\nprint(best_hps.get('activation'))","metadata":{"id":"G9QpATKotWz0","outputId":"64301832-987d-4666-8353-c3ea50ef00d0","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2022-11-10T21:35:45.439664Z","iopub.execute_input":"2022-11-10T21:35:45.440046Z","iopub.status.idle":"2022-11-10T21:35:45.447629Z","shell.execute_reply.started":"2022-11-10T21:35:45.440012Z","shell.execute_reply":"2022-11-10T21:35:45.446558Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"1024\n0.001\n0.4\n0.6\nelu\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(224, 224, 3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = Flatten()(x)\nx = tf.keras.layers.Dropout(0.4)(x)\nx = tf.keras.layers.Dense(units=1024, activation='elu')(x)\nx = tf.keras.layers.Dropout(0.6)(x)\nprediction = Dense(10, activation='softmax')(x)\nmodel = tf.keras.Model(inputs=inputs, outputs=prediction)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 0.001),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\nmodel_checkpoints = [\n    tf.keras.callbacks.ModelCheckpoint(filepath = 'hyperparameter_adam.h5', \n    verbose=1, save_best_only=True, save_weights_only=False, mode='max', monitor='val_accuracy') \n    ]\n\nhistory = model.fit(train_dataset,epochs=50, validation_data = validation_dataset, callbacks = [model_checkpoints])\n","metadata":{"id":"Jcnatxn0tWz0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a097ca9-98f9-4ee6-ae8a-bdd1fdcd4eff","execution":{"iopub.status.busy":"2022-11-10T21:37:03.694976Z","iopub.execute_input":"2022-11-10T21:37:03.695393Z","iopub.status.idle":"2022-11-10T21:40:53.094926Z","shell.execute_reply.started":"2022-11-10T21:37:03.695358Z","shell.execute_reply":"2022-11-10T21:40:53.093756Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/50\n22/22 [==============================] - 5s 164ms/step - loss: 44.9413 - accuracy: 0.3829 - val_loss: 18.8146 - val_accuracy: 0.6633\n\nEpoch 00001: val_accuracy improved from -inf to 0.66333, saving model to hyperparameter_adam.h5\nEpoch 2/50\n22/22 [==============================] - 4s 152ms/step - loss: 16.3732 - accuracy: 0.6429 - val_loss: 16.3333 - val_accuracy: 0.6500\n\nEpoch 00002: val_accuracy did not improve from 0.66333\nEpoch 3/50\n22/22 [==============================] - 4s 171ms/step - loss: 10.7830 - accuracy: 0.6657 - val_loss: 15.0050 - val_accuracy: 0.6567\n\nEpoch 00003: val_accuracy did not improve from 0.66333\nEpoch 4/50\n22/22 [==============================] - 4s 156ms/step - loss: 6.3144 - accuracy: 0.7329 - val_loss: 8.3161 - val_accuracy: 0.7133\n\nEpoch 00004: val_accuracy improved from 0.66333 to 0.71333, saving model to hyperparameter_adam.h5\nEpoch 5/50\n22/22 [==============================] - 4s 149ms/step - loss: 4.8127 - accuracy: 0.7471 - val_loss: 6.2151 - val_accuracy: 0.7333\n\nEpoch 00005: val_accuracy improved from 0.71333 to 0.73333, saving model to hyperparameter_adam.h5\nEpoch 6/50\n22/22 [==============================] - 4s 152ms/step - loss: 3.4807 - accuracy: 0.7686 - val_loss: 5.0118 - val_accuracy: 0.7067\n\nEpoch 00006: val_accuracy did not improve from 0.73333\nEpoch 7/50\n22/22 [==============================] - 4s 152ms/step - loss: 3.0404 - accuracy: 0.7743 - val_loss: 5.4574 - val_accuracy: 0.6800\n\nEpoch 00007: val_accuracy did not improve from 0.73333\nEpoch 8/50\n22/22 [==============================] - 4s 149ms/step - loss: 2.6036 - accuracy: 0.7829 - val_loss: 4.3213 - val_accuracy: 0.7133\n\nEpoch 00008: val_accuracy did not improve from 0.73333\nEpoch 9/50\n22/22 [==============================] - 4s 151ms/step - loss: 1.7981 - accuracy: 0.8243 - val_loss: 3.6178 - val_accuracy: 0.7333\n\nEpoch 00009: val_accuracy did not improve from 0.73333\nEpoch 10/50\n22/22 [==============================] - 4s 162ms/step - loss: 1.7189 - accuracy: 0.8114 - val_loss: 3.7305 - val_accuracy: 0.7333\n\nEpoch 00010: val_accuracy did not improve from 0.73333\nEpoch 11/50\n22/22 [==============================] - 4s 150ms/step - loss: 2.0470 - accuracy: 0.8000 - val_loss: 4.4333 - val_accuracy: 0.6967\n\nEpoch 00011: val_accuracy did not improve from 0.73333\nEpoch 12/50\n22/22 [==============================] - 4s 152ms/step - loss: 1.3752 - accuracy: 0.8286 - val_loss: 3.3904 - val_accuracy: 0.7233\n\nEpoch 00012: val_accuracy did not improve from 0.73333\nEpoch 13/50\n22/22 [==============================] - 4s 148ms/step - loss: 1.5963 - accuracy: 0.8229 - val_loss: 3.2668 - val_accuracy: 0.7233\n\nEpoch 00013: val_accuracy did not improve from 0.73333\nEpoch 14/50\n22/22 [==============================] - 4s 153ms/step - loss: 1.3709 - accuracy: 0.8343 - val_loss: 3.3587 - val_accuracy: 0.7300\n\nEpoch 00014: val_accuracy did not improve from 0.73333\nEpoch 15/50\n22/22 [==============================] - 4s 151ms/step - loss: 1.3542 - accuracy: 0.8571 - val_loss: 4.1666 - val_accuracy: 0.7233\n\nEpoch 00015: val_accuracy did not improve from 0.73333\nEpoch 16/50\n22/22 [==============================] - 4s 159ms/step - loss: 1.6673 - accuracy: 0.8357 - val_loss: 3.8266 - val_accuracy: 0.7267\n\nEpoch 00016: val_accuracy did not improve from 0.73333\nEpoch 17/50\n22/22 [==============================] - 4s 171ms/step - loss: 1.3567 - accuracy: 0.8371 - val_loss: 3.8748 - val_accuracy: 0.7067\n\nEpoch 00017: val_accuracy did not improve from 0.73333\nEpoch 18/50\n22/22 [==============================] - 4s 151ms/step - loss: 1.2938 - accuracy: 0.8586 - val_loss: 3.8354 - val_accuracy: 0.7067\n\nEpoch 00018: val_accuracy did not improve from 0.73333\nEpoch 19/50\n22/22 [==============================] - 4s 154ms/step - loss: 1.0894 - accuracy: 0.8557 - val_loss: 4.0326 - val_accuracy: 0.7000\n\nEpoch 00019: val_accuracy did not improve from 0.73333\nEpoch 20/50\n22/22 [==============================] - 4s 151ms/step - loss: 1.4081 - accuracy: 0.8357 - val_loss: 3.0587 - val_accuracy: 0.7233\n\nEpoch 00020: val_accuracy did not improve from 0.73333\nEpoch 21/50\n22/22 [==============================] - 4s 156ms/step - loss: 1.6219 - accuracy: 0.8414 - val_loss: 3.8702 - val_accuracy: 0.6967\n\nEpoch 00021: val_accuracy did not improve from 0.73333\nEpoch 22/50\n22/22 [==============================] - 4s 150ms/step - loss: 1.2548 - accuracy: 0.8471 - val_loss: 4.2320 - val_accuracy: 0.7033\n\nEpoch 00022: val_accuracy did not improve from 0.73333\nEpoch 23/50\n22/22 [==============================] - 4s 157ms/step - loss: 1.3363 - accuracy: 0.8471 - val_loss: 4.2497 - val_accuracy: 0.7000\n\nEpoch 00023: val_accuracy did not improve from 0.73333\nEpoch 24/50\n22/22 [==============================] - 4s 165ms/step - loss: 1.2536 - accuracy: 0.8829 - val_loss: 4.1751 - val_accuracy: 0.7367\n\nEpoch 00024: val_accuracy improved from 0.73333 to 0.73667, saving model to hyperparameter_adam.h5\nEpoch 25/50\n22/22 [==============================] - 4s 151ms/step - loss: 1.1162 - accuracy: 0.8743 - val_loss: 4.0470 - val_accuracy: 0.7233\n\nEpoch 00025: val_accuracy did not improve from 0.73667\nEpoch 26/50\n22/22 [==============================] - 4s 153ms/step - loss: 1.1017 - accuracy: 0.8714 - val_loss: 3.8684 - val_accuracy: 0.7467\n\nEpoch 00026: val_accuracy improved from 0.73667 to 0.74667, saving model to hyperparameter_adam.h5\nEpoch 27/50\n22/22 [==============================] - 4s 150ms/step - loss: 1.3101 - accuracy: 0.8514 - val_loss: 4.8096 - val_accuracy: 0.7200\n\nEpoch 00027: val_accuracy did not improve from 0.74667\nEpoch 28/50\n22/22 [==============================] - 4s 151ms/step - loss: 1.3616 - accuracy: 0.8614 - val_loss: 4.3443 - val_accuracy: 0.7400\n\nEpoch 00028: val_accuracy did not improve from 0.74667\nEpoch 29/50\n22/22 [==============================] - 4s 149ms/step - loss: 1.2874 - accuracy: 0.8571 - val_loss: 4.5698 - val_accuracy: 0.7367\n\nEpoch 00029: val_accuracy did not improve from 0.74667\nEpoch 30/50\n22/22 [==============================] - 4s 150ms/step - loss: 1.1103 - accuracy: 0.8829 - val_loss: 4.4843 - val_accuracy: 0.7367\n\nEpoch 00030: val_accuracy did not improve from 0.74667\nEpoch 31/50\n22/22 [==============================] - 4s 161ms/step - loss: 1.3605 - accuracy: 0.8586 - val_loss: 4.9724 - val_accuracy: 0.7300\n\nEpoch 00031: val_accuracy did not improve from 0.74667\nEpoch 32/50\n22/22 [==============================] - 4s 154ms/step - loss: 1.1885 - accuracy: 0.8943 - val_loss: 4.5977 - val_accuracy: 0.7400\n\nEpoch 00032: val_accuracy did not improve from 0.74667\nEpoch 33/50\n22/22 [==============================] - 4s 150ms/step - loss: 1.2940 - accuracy: 0.8800 - val_loss: 4.0338 - val_accuracy: 0.7100\n\nEpoch 00033: val_accuracy did not improve from 0.74667\nEpoch 34/50\n22/22 [==============================] - 4s 151ms/step - loss: 1.4558 - accuracy: 0.8629 - val_loss: 3.9827 - val_accuracy: 0.7467\n\nEpoch 00034: val_accuracy did not improve from 0.74667\nEpoch 35/50\n22/22 [==============================] - 4s 153ms/step - loss: 1.2633 - accuracy: 0.8643 - val_loss: 3.8799 - val_accuracy: 0.7200\n\nEpoch 00035: val_accuracy did not improve from 0.74667\nEpoch 36/50\n22/22 [==============================] - 4s 150ms/step - loss: 1.3127 - accuracy: 0.8743 - val_loss: 3.8538 - val_accuracy: 0.7567\n\nEpoch 00036: val_accuracy improved from 0.74667 to 0.75667, saving model to hyperparameter_adam.h5\nEpoch 37/50\n22/22 [==============================] - 4s 146ms/step - loss: 1.0856 - accuracy: 0.8743 - val_loss: 4.2936 - val_accuracy: 0.7533\n\nEpoch 00037: val_accuracy did not improve from 0.75667\nEpoch 38/50\n22/22 [==============================] - 4s 185ms/step - loss: 1.3124 - accuracy: 0.8757 - val_loss: 3.8784 - val_accuracy: 0.7233\n\nEpoch 00038: val_accuracy did not improve from 0.75667\nEpoch 39/50\n22/22 [==============================] - 4s 150ms/step - loss: 0.7675 - accuracy: 0.8986 - val_loss: 4.2652 - val_accuracy: 0.7733\n\nEpoch 00039: val_accuracy improved from 0.75667 to 0.77333, saving model to hyperparameter_adam.h5\nEpoch 40/50\n22/22 [==============================] - 4s 160ms/step - loss: 1.2659 - accuracy: 0.8843 - val_loss: 5.8225 - val_accuracy: 0.6900\n\nEpoch 00040: val_accuracy did not improve from 0.77333\nEpoch 41/50\n22/22 [==============================] - 4s 148ms/step - loss: 1.2005 - accuracy: 0.8786 - val_loss: 4.2828 - val_accuracy: 0.7467\n\nEpoch 00041: val_accuracy did not improve from 0.77333\nEpoch 42/50\n22/22 [==============================] - 4s 151ms/step - loss: 1.3252 - accuracy: 0.8800 - val_loss: 4.9228 - val_accuracy: 0.7367\n\nEpoch 00042: val_accuracy did not improve from 0.77333\nEpoch 43/50\n22/22 [==============================] - 4s 148ms/step - loss: 1.2583 - accuracy: 0.8843 - val_loss: 4.7332 - val_accuracy: 0.7467\n\nEpoch 00043: val_accuracy did not improve from 0.77333\nEpoch 44/50\n22/22 [==============================] - 4s 151ms/step - loss: 1.8011 - accuracy: 0.8686 - val_loss: 5.4550 - val_accuracy: 0.7400\n\nEpoch 00044: val_accuracy did not improve from 0.77333\nEpoch 45/50\n22/22 [==============================] - 4s 154ms/step - loss: 1.4360 - accuracy: 0.8886 - val_loss: 5.6377 - val_accuracy: 0.7400\n\nEpoch 00045: val_accuracy did not improve from 0.77333\nEpoch 46/50\n22/22 [==============================] - 4s 145ms/step - loss: 1.7320 - accuracy: 0.8857 - val_loss: 6.0252 - val_accuracy: 0.7300\n\nEpoch 00046: val_accuracy did not improve from 0.77333\nEpoch 47/50\n22/22 [==============================] - 4s 159ms/step - loss: 1.1707 - accuracy: 0.9043 - val_loss: 5.8330 - val_accuracy: 0.7333\n\nEpoch 00047: val_accuracy did not improve from 0.77333\nEpoch 48/50\n22/22 [==============================] - 4s 148ms/step - loss: 1.6330 - accuracy: 0.8800 - val_loss: 5.2943 - val_accuracy: 0.7433\n\nEpoch 00048: val_accuracy did not improve from 0.77333\nEpoch 49/50\n22/22 [==============================] - 4s 149ms/step - loss: 1.2351 - accuracy: 0.8800 - val_loss: 5.9397 - val_accuracy: 0.7267\n\nEpoch 00049: val_accuracy did not improve from 0.77333\nEpoch 50/50\n22/22 [==============================] - 4s 158ms/step - loss: 1.1479 - accuracy: 0.8857 - val_loss: 5.9184 - val_accuracy: 0.7267\n\nEpoch 00050: val_accuracy did not improve from 0.77333\n","output_type":"stream"}]},{"cell_type":"code","source":"adam_model.evaluate(test_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAneAGFLAT-m","outputId":"81e5e918-6e97-44da-a393-2564b1176704","execution":{"iopub.status.busy":"2022-11-10T22:00:59.453649Z","iopub.execute_input":"2022-11-10T22:00:59.454033Z","iopub.status.idle":"2022-11-10T22:01:06.457314Z","shell.execute_reply.started":"2022-11-10T22:00:59.453999Z","shell.execute_reply":"2022-11-10T22:01:06.456151Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 7s 7s/step - loss: 2.2028 - accuracy: 0.7333\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"[2.2028489112854004, 0.7333333492279053]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Transfer Learning and tune the hyperparameters with frozen layers (SGD optimizer)","metadata":{"id":"Qk57GS3-x_AG"}},{"cell_type":"code","source":"def model_builder_SGD(hp):\n    \n    hp_units = hp.Choice('units', [16, 32, 64, 128, 256, 512, 1024])\n    hp_lr = hp.Choice('lr', [1e-2, 1e-3, 1e-4])\n    hp_ratio1 = hp.Choice('ratio1', [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])\n    hp_ratio2 = hp.Choice('ratio2', [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])\n    hp_activation = hp.Choice('activation', ['relu', 'elu'])\n    \n    inputs = tf.keras.Input(shape=(224, 224, 3))\n    \n    x = data_augmentation(inputs)\n    x = preprocess_input(x)\n    x = base_model(x, training=False)\n    x = Flatten()(x)\n    x = tf.keras.layers.Dropout(hp_ratio1)(x)\n    x = tf.keras.layers.Dense(units=hp_units, activation=hp_activation)(x)\n    x = tf.keras.layers.Dropout(hp_ratio2)(x)\n    prediction = Dense(10, activation='softmax')(x)\n    model = tf.keras.Model(inputs=inputs, outputs=prediction)\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.SGD(learning_rate=hp_lr),\n        loss=tf.keras.losses.CategoricalCrossentropy(),\n        metrics=['accuracy']\n    )\n\n    return model","metadata":{"id":"3FzjCpZ4yCGA","execution":{"iopub.status.busy":"2022-11-11T08:08:52.648330Z","iopub.execute_input":"2022-11-11T08:08:52.649046Z","iopub.status.idle":"2022-11-11T08:08:52.658902Z","shell.execute_reply.started":"2022-11-11T08:08:52.649011Z","shell.execute_reply":"2022-11-11T08:08:52.657816Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tuner2 = kt.Hyperband(\n    model_builder_SGD,\n    objective='val_accuracy',\n    max_epochs=10,\n    directory=\"./\",\n    project_name='vgg_sgd'\n)\n\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\ntuner2.search(train_dataset, epochs=50,validation_data=validation_dataset, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner2.get_best_hyperparameters(num_trials=1)[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7AldXtQeyD7C","outputId":"7ef1cfc5-8a69-4821-e5c3-0c076f15d230","execution":{"iopub.status.busy":"2022-11-10T21:42:03.042795Z","iopub.execute_input":"2022-11-10T21:42:03.043194Z","iopub.status.idle":"2022-11-10T21:52:40.514921Z","shell.execute_reply.started":"2022-11-10T21:42:03.043160Z","shell.execute_reply":"2022-11-10T21:52:40.513518Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Trial 30 Complete [00h 00m 48s]\nval_accuracy: 0.11999999731779099\n\nBest val_accuracy So Far: 0.7233333587646484\nTotal elapsed time: 00h 10m 37s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(best_hps.get('units'))\nprint(best_hps.get('lr'))\nprint(best_hps.get('ratio1'))\nprint(best_hps.get('ratio2'))\nprint(best_hps.get('activation'))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzKdUcWgyFxG","outputId":"7b3f5326-9720-43b6-b80b-3d0187212d31","execution":{"iopub.status.busy":"2022-11-10T21:55:34.571670Z","iopub.execute_input":"2022-11-10T21:55:34.572939Z","iopub.status.idle":"2022-11-10T21:55:34.580676Z","shell.execute_reply.started":"2022-11-10T21:55:34.572894Z","shell.execute_reply":"2022-11-10T21:55:34.579573Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"1024\n0.01\n0.5\n0.1\nrelu\n","output_type":"stream"}]},{"cell_type":"code","source":"x = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = Flatten()(x)\nx = tf.keras.layers.Dropout(0.5)(x)\nx = tf.keras.layers.Dense(units=1024, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.1)(x)\nprediction = Dense(10, activation='softmax')(x)\nmodel = tf.keras.Model(inputs=inputs, outputs=prediction)\n\nmodel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate= 0.01),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\nmodel_checkpoints = [\n    tf.keras.callbacks.ModelCheckpoint(filepath = 'hyperparameter_sgd.h5', \n    verbose=1, save_best_only=True, save_weights_only=False, mode='max', monitor='val_accuracy') \n    ]\n\nhistory = model.fit(train_dataset,epochs=50, validation_data = validation_dataset, callbacks = [model_checkpoints])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrn-NytcyJQb","outputId":"7a7a1ddc-4a8f-4a52-b187-05a7f88e019e","execution":{"iopub.status.busy":"2022-11-10T21:56:29.712573Z","iopub.execute_input":"2022-11-10T21:56:29.712969Z","iopub.status.idle":"2022-11-10T22:00:20.669656Z","shell.execute_reply.started":"2022-11-10T21:56:29.712935Z","shell.execute_reply":"2022-11-10T22:00:20.668408Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch 1/50\n22/22 [==============================] - 5s 161ms/step - loss: 39.2008 - accuracy: 0.3300 - val_loss: 1.7007 - val_accuracy: 0.5100\n\nEpoch 00001: val_accuracy improved from -inf to 0.51000, saving model to hyperparameter_sgd.h5\nEpoch 2/50\n22/22 [==============================] - 4s 163ms/step - loss: 1.9000 - accuracy: 0.5414 - val_loss: 1.5716 - val_accuracy: 0.5567\n\nEpoch 00002: val_accuracy improved from 0.51000 to 0.55667, saving model to hyperparameter_sgd.h5\nEpoch 3/50\n22/22 [==============================] - 4s 150ms/step - loss: 1.3649 - accuracy: 0.6229 - val_loss: 1.5206 - val_accuracy: 0.5867\n\nEpoch 00003: val_accuracy improved from 0.55667 to 0.58667, saving model to hyperparameter_sgd.h5\nEpoch 4/50\n22/22 [==============================] - 4s 157ms/step - loss: 1.0865 - accuracy: 0.7000 - val_loss: 1.3758 - val_accuracy: 0.6600\n\nEpoch 00004: val_accuracy improved from 0.58667 to 0.66000, saving model to hyperparameter_sgd.h5\nEpoch 5/50\n22/22 [==============================] - 4s 149ms/step - loss: 0.9593 - accuracy: 0.7314 - val_loss: 1.5183 - val_accuracy: 0.6333\n\nEpoch 00005: val_accuracy did not improve from 0.66000\nEpoch 6/50\n22/22 [==============================] - 4s 159ms/step - loss: 0.8014 - accuracy: 0.7771 - val_loss: 1.4388 - val_accuracy: 0.6533\n\nEpoch 00006: val_accuracy did not improve from 0.66000\nEpoch 7/50\n22/22 [==============================] - 4s 146ms/step - loss: 0.7300 - accuracy: 0.7986 - val_loss: 1.3192 - val_accuracy: 0.6700\n\nEpoch 00007: val_accuracy improved from 0.66000 to 0.67000, saving model to hyperparameter_sgd.h5\nEpoch 8/50\n22/22 [==============================] - 4s 152ms/step - loss: 0.7799 - accuracy: 0.7814 - val_loss: 1.4420 - val_accuracy: 0.6733\n\nEpoch 00008: val_accuracy improved from 0.67000 to 0.67333, saving model to hyperparameter_sgd.h5\nEpoch 9/50\n22/22 [==============================] - 4s 148ms/step - loss: 0.6722 - accuracy: 0.8000 - val_loss: 1.3986 - val_accuracy: 0.6700\n\nEpoch 00009: val_accuracy did not improve from 0.67333\nEpoch 10/50\n22/22 [==============================] - 4s 150ms/step - loss: 0.5490 - accuracy: 0.8257 - val_loss: 1.5898 - val_accuracy: 0.6267\n\nEpoch 00010: val_accuracy did not improve from 0.67333\nEpoch 11/50\n22/22 [==============================] - 4s 155ms/step - loss: 0.5438 - accuracy: 0.8429 - val_loss: 1.4419 - val_accuracy: 0.6867\n\nEpoch 00011: val_accuracy improved from 0.67333 to 0.68667, saving model to hyperparameter_sgd.h5\nEpoch 12/50\n22/22 [==============================] - 4s 151ms/step - loss: 0.4082 - accuracy: 0.8686 - val_loss: 1.4188 - val_accuracy: 0.6933\n\nEpoch 00012: val_accuracy improved from 0.68667 to 0.69333, saving model to hyperparameter_sgd.h5\nEpoch 13/50\n22/22 [==============================] - 4s 152ms/step - loss: 0.4169 - accuracy: 0.8800 - val_loss: 1.6160 - val_accuracy: 0.6967\n\nEpoch 00013: val_accuracy improved from 0.69333 to 0.69667, saving model to hyperparameter_sgd.h5\nEpoch 14/50\n22/22 [==============================] - 4s 151ms/step - loss: 0.3746 - accuracy: 0.8757 - val_loss: 1.5093 - val_accuracy: 0.7100\n\nEpoch 00014: val_accuracy improved from 0.69667 to 0.71000, saving model to hyperparameter_sgd.h5\nEpoch 15/50\n22/22 [==============================] - 4s 167ms/step - loss: 0.4191 - accuracy: 0.8771 - val_loss: 1.5399 - val_accuracy: 0.6833\n\nEpoch 00015: val_accuracy did not improve from 0.71000\nEpoch 16/50\n22/22 [==============================] - 4s 148ms/step - loss: 0.3896 - accuracy: 0.8843 - val_loss: 1.5057 - val_accuracy: 0.6933\n\nEpoch 00016: val_accuracy did not improve from 0.71000\nEpoch 17/50\n22/22 [==============================] - 4s 150ms/step - loss: 0.4664 - accuracy: 0.8686 - val_loss: 1.4359 - val_accuracy: 0.7100\n\nEpoch 00017: val_accuracy did not improve from 0.71000\nEpoch 18/50\n22/22 [==============================] - 4s 151ms/step - loss: 0.3413 - accuracy: 0.9100 - val_loss: 1.4753 - val_accuracy: 0.7167\n\nEpoch 00018: val_accuracy improved from 0.71000 to 0.71667, saving model to hyperparameter_sgd.h5\nEpoch 19/50\n22/22 [==============================] - 4s 149ms/step - loss: 0.2895 - accuracy: 0.9186 - val_loss: 1.5231 - val_accuracy: 0.6933\n\nEpoch 00019: val_accuracy did not improve from 0.71667\nEpoch 20/50\n22/22 [==============================] - 4s 155ms/step - loss: 0.2504 - accuracy: 0.9257 - val_loss: 1.4798 - val_accuracy: 0.7067\n\nEpoch 00020: val_accuracy did not improve from 0.71667\nEpoch 21/50\n22/22 [==============================] - 4s 146ms/step - loss: 0.2716 - accuracy: 0.9286 - val_loss: 1.4329 - val_accuracy: 0.7000\n\nEpoch 00021: val_accuracy did not improve from 0.71667\nEpoch 22/50\n22/22 [==============================] - 4s 166ms/step - loss: 0.2320 - accuracy: 0.9271 - val_loss: 1.5519 - val_accuracy: 0.6933\n\nEpoch 00022: val_accuracy did not improve from 0.71667\nEpoch 23/50\n22/22 [==============================] - 4s 149ms/step - loss: 0.2188 - accuracy: 0.9386 - val_loss: 1.5956 - val_accuracy: 0.7100\n\nEpoch 00023: val_accuracy did not improve from 0.71667\nEpoch 24/50\n22/22 [==============================] - 4s 145ms/step - loss: 0.2043 - accuracy: 0.9386 - val_loss: 1.7171 - val_accuracy: 0.6833\n\nEpoch 00024: val_accuracy did not improve from 0.71667\nEpoch 25/50\n22/22 [==============================] - 4s 153ms/step - loss: 0.1601 - accuracy: 0.9500 - val_loss: 1.6990 - val_accuracy: 0.7267\n\nEpoch 00025: val_accuracy improved from 0.71667 to 0.72667, saving model to hyperparameter_sgd.h5\nEpoch 26/50\n22/22 [==============================] - 4s 151ms/step - loss: 0.1957 - accuracy: 0.9386 - val_loss: 1.6858 - val_accuracy: 0.7233\n\nEpoch 00026: val_accuracy did not improve from 0.72667\nEpoch 27/50\n22/22 [==============================] - 4s 157ms/step - loss: 0.1586 - accuracy: 0.9429 - val_loss: 1.7255 - val_accuracy: 0.7167\n\nEpoch 00027: val_accuracy did not improve from 0.72667\nEpoch 28/50\n22/22 [==============================] - 4s 151ms/step - loss: 0.1892 - accuracy: 0.9529 - val_loss: 1.7162 - val_accuracy: 0.7333\n\nEpoch 00028: val_accuracy improved from 0.72667 to 0.73333, saving model to hyperparameter_sgd.h5\nEpoch 29/50\n22/22 [==============================] - 4s 158ms/step - loss: 0.1923 - accuracy: 0.9500 - val_loss: 1.8259 - val_accuracy: 0.7233\n\nEpoch 00029: val_accuracy did not improve from 0.73333\nEpoch 30/50\n22/22 [==============================] - 4s 159ms/step - loss: 0.1994 - accuracy: 0.9357 - val_loss: 1.7005 - val_accuracy: 0.7433\n\nEpoch 00030: val_accuracy improved from 0.73333 to 0.74333, saving model to hyperparameter_sgd.h5\nEpoch 31/50\n22/22 [==============================] - 4s 148ms/step - loss: 0.1817 - accuracy: 0.9443 - val_loss: 1.7079 - val_accuracy: 0.7233\n\nEpoch 00031: val_accuracy did not improve from 0.74333\nEpoch 32/50\n22/22 [==============================] - 4s 158ms/step - loss: 0.1598 - accuracy: 0.9543 - val_loss: 1.8564 - val_accuracy: 0.7167\n\nEpoch 00032: val_accuracy did not improve from 0.74333\nEpoch 33/50\n22/22 [==============================] - 4s 149ms/step - loss: 0.0890 - accuracy: 0.9757 - val_loss: 1.7176 - val_accuracy: 0.7100\n\nEpoch 00033: val_accuracy did not improve from 0.74333\nEpoch 34/50\n22/22 [==============================] - 4s 148ms/step - loss: 0.0786 - accuracy: 0.9700 - val_loss: 1.8927 - val_accuracy: 0.7167\n\nEpoch 00034: val_accuracy did not improve from 0.74333\nEpoch 35/50\n22/22 [==============================] - 4s 145ms/step - loss: 0.0975 - accuracy: 0.9714 - val_loss: 1.8447 - val_accuracy: 0.7400\n\nEpoch 00035: val_accuracy did not improve from 0.74333\nEpoch 36/50\n22/22 [==============================] - 4s 166ms/step - loss: 0.0741 - accuracy: 0.9729 - val_loss: 1.8696 - val_accuracy: 0.7500\n\nEpoch 00036: val_accuracy improved from 0.74333 to 0.75000, saving model to hyperparameter_sgd.h5\nEpoch 37/50\n22/22 [==============================] - 4s 164ms/step - loss: 0.0807 - accuracy: 0.9757 - val_loss: 1.7102 - val_accuracy: 0.7533\n\nEpoch 00037: val_accuracy improved from 0.75000 to 0.75333, saving model to hyperparameter_sgd.h5\nEpoch 38/50\n22/22 [==============================] - 4s 148ms/step - loss: 0.1362 - accuracy: 0.9643 - val_loss: 1.8245 - val_accuracy: 0.7267\n\nEpoch 00038: val_accuracy did not improve from 0.75333\nEpoch 39/50\n22/22 [==============================] - 4s 150ms/step - loss: 0.1435 - accuracy: 0.9529 - val_loss: 1.9303 - val_accuracy: 0.7067\n\nEpoch 00039: val_accuracy did not improve from 0.75333\nEpoch 40/50\n22/22 [==============================] - 4s 147ms/step - loss: 0.1083 - accuracy: 0.9586 - val_loss: 1.7092 - val_accuracy: 0.7400\n\nEpoch 00040: val_accuracy did not improve from 0.75333\nEpoch 41/50\n22/22 [==============================] - 4s 149ms/step - loss: 0.1485 - accuracy: 0.9614 - val_loss: 1.7854 - val_accuracy: 0.7233\n\nEpoch 00041: val_accuracy did not improve from 0.75333\nEpoch 42/50\n22/22 [==============================] - 4s 148ms/step - loss: 0.0626 - accuracy: 0.9800 - val_loss: 1.9148 - val_accuracy: 0.7133\n\nEpoch 00042: val_accuracy did not improve from 0.75333\nEpoch 43/50\n22/22 [==============================] - 4s 151ms/step - loss: 0.0600 - accuracy: 0.9800 - val_loss: 1.9049 - val_accuracy: 0.7367\n\nEpoch 00043: val_accuracy did not improve from 0.75333\nEpoch 44/50\n22/22 [==============================] - 4s 149ms/step - loss: 0.1412 - accuracy: 0.9700 - val_loss: 2.0265 - val_accuracy: 0.7133\n\nEpoch 00044: val_accuracy did not improve from 0.75333\nEpoch 45/50\n22/22 [==============================] - 4s 151ms/step - loss: 0.0997 - accuracy: 0.9743 - val_loss: 1.9260 - val_accuracy: 0.7500\n\nEpoch 00045: val_accuracy did not improve from 0.75333\nEpoch 46/50\n22/22 [==============================] - 4s 149ms/step - loss: 0.0759 - accuracy: 0.9800 - val_loss: 1.9001 - val_accuracy: 0.7400\n\nEpoch 00046: val_accuracy did not improve from 0.75333\nEpoch 47/50\n22/22 [==============================] - 4s 166ms/step - loss: 0.1276 - accuracy: 0.9700 - val_loss: 1.9202 - val_accuracy: 0.7400\n\nEpoch 00047: val_accuracy did not improve from 0.75333\nEpoch 48/50\n22/22 [==============================] - 4s 147ms/step - loss: 0.0628 - accuracy: 0.9800 - val_loss: 2.0567 - val_accuracy: 0.7500\n\nEpoch 00048: val_accuracy did not improve from 0.75333\nEpoch 49/50\n22/22 [==============================] - 4s 150ms/step - loss: 0.0818 - accuracy: 0.9729 - val_loss: 2.0833 - val_accuracy: 0.7400\n\nEpoch 00049: val_accuracy did not improve from 0.75333\nEpoch 50/50\n22/22 [==============================] - 4s 162ms/step - loss: 0.0588 - accuracy: 0.9786 - val_loss: 2.1717 - val_accuracy: 0.7300\n\nEpoch 00050: val_accuracy did not improve from 0.75333\n","output_type":"stream"}]},{"cell_type":"code","source":"sgd_model.evaluate(test_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01SLhNAIAZ0B","outputId":"71546c31-419c-416d-92f5-1b0cff642b97","execution":{"iopub.status.busy":"2022-11-10T22:01:27.517266Z","iopub.execute_input":"2022-11-10T22:01:27.517629Z","iopub.status.idle":"2022-11-10T22:01:30.531415Z","shell.execute_reply.started":"2022-11-10T22:01:27.517598Z","shell.execute_reply":"2022-11-10T22:01:30.530463Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 3s 3s/step - loss: 1.5944 - accuracy: 0.6333\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"[1.5944373607635498, 0.6333333253860474]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Transfer Learning and tune the hyperparameters with some unfrozen layers (Adam optimizer)","metadata":{"id":"VPQlhbx-Aes2"}},{"cell_type":"code","source":"base_model.trainable = True\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\ndef model_builder_Adam_unfrozen(hp):\n    \n    hp_lr = hp.Choice('lr', [1e-2, 1e-3, 1e-4])\n    hp_layers = hp.Choice('layers', [2,4,6,8,10,12,14,16,18,20,22])\n\n    # Fine-tune from this layer onwards\n    fine_tune_at = hp_layers\n\n    # Freeze all the layers before the `fine_tune_at` layer\n    for layer in base_model.layers[:fine_tune_at]:\n      layer.trainable = False\n    \n    adam_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= hp_lr),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\n    return adam_model","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSByPEOGGGze","outputId":"6ce0ff7e-abb6-4ed3-f834-f6cdf5366cfd","execution":{"iopub.status.busy":"2022-11-11T08:44:44.666103Z","iopub.execute_input":"2022-11-11T08:44:44.666647Z","iopub.status.idle":"2022-11-11T08:44:44.676077Z","shell.execute_reply.started":"2022-11-11T08:44:44.666595Z","shell.execute_reply":"2022-11-11T08:44:44.674300Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Number of layers in the base model:  22\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner4 = kt.Hyperband(\n    model_builder_Adam_unfrozen,\n    objective='val_accuracy',\n    max_epochs=10,\n    directory=\"./\",\n    project_name='vgg_adam_unfrozen'\n)\n\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\ntuner4.search(train_dataset, epochs=50,validation_data=validation_dataset, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner4.get_best_hyperparameters(num_trials=1)[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"naZDQDCjLOiq","outputId":"4500ac65-9090-433d-cc46-caabd971df39","execution":{"iopub.status.busy":"2022-11-10T22:13:45.046718Z","iopub.execute_input":"2022-11-10T22:13:45.047101Z","iopub.status.idle":"2022-11-10T22:25:52.950625Z","shell.execute_reply.started":"2022-11-10T22:13:45.047066Z","shell.execute_reply":"2022-11-10T22:25:52.949348Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Trial 30 Complete [00h 00m 27s]\nval_accuracy: 0.5400000214576721\n\nBest val_accuracy So Far: 0.6100000143051147\nTotal elapsed time: 00h 12m 07s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(best_hps.get('lr'))\nprint(best_hps.get('layers'))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hmPZBJOLYS0","outputId":"c3e56725-785d-4fb1-b191-2d7cb84aff80","execution":{"iopub.status.busy":"2022-11-10T22:26:51.555463Z","iopub.execute_input":"2022-11-10T22:26:51.555898Z","iopub.status.idle":"2022-11-10T22:26:51.563059Z","shell.execute_reply.started":"2022-11-10T22:26:51.555860Z","shell.execute_reply":"2022-11-10T22:26:51.561950Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"0.001\n14\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model.trainable = True\nfine_tune_at = 14\n\n    # Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n    \nadam_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 0.001),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\n\nfine_tune_epochs = 20\ntotal_epochs =  50 + fine_tune_epochs\n\n\nmodel_checkpoints = [\n    tf.keras.callbacks.ModelCheckpoint(filepath = './hyperparameter_adam_unfrozen.h5', \n    verbose=1, save_best_only=True, save_weights_only=False, mode='max', monitor='val_accuracy') \n    ]\n\nhistory_fine = adam_model.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch=50,\n                         validation_data=validation_dataset,\n                             callbacks = [model_checkpoints])\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eN9-6HuIPRH1","outputId":"c6cd7316-ea98-48f0-9f7c-c8f652c779b9","execution":{"iopub.status.busy":"2022-11-10T22:27:58.164340Z","iopub.execute_input":"2022-11-10T22:27:58.164731Z","iopub.status.idle":"2022-11-10T22:29:30.161037Z","shell.execute_reply.started":"2022-11-10T22:27:58.164695Z","shell.execute_reply":"2022-11-10T22:29:30.159606Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Epoch 51/70\n22/22 [==============================] - 5s 159ms/step - loss: 5.0329 - accuracy: 0.4429 - val_loss: 6.3353 - val_accuracy: 0.5300\n\nEpoch 00051: val_accuracy improved from -inf to 0.53000, saving model to ./hyperparameter_adam_unfrozen.h5\nEpoch 52/70\n22/22 [==============================] - 4s 171ms/step - loss: 4.1229 - accuracy: 0.4629 - val_loss: 6.4080 - val_accuracy: 0.5233\n\nEpoch 00052: val_accuracy did not improve from 0.53000\nEpoch 53/70\n22/22 [==============================] - 4s 152ms/step - loss: 4.4956 - accuracy: 0.4429 - val_loss: 6.4600 - val_accuracy: 0.5333\n\nEpoch 00053: val_accuracy improved from 0.53000 to 0.53333, saving model to ./hyperparameter_adam_unfrozen.h5\nEpoch 54/70\n22/22 [==============================] - 4s 150ms/step - loss: 4.4011 - accuracy: 0.4471 - val_loss: 6.4091 - val_accuracy: 0.5067\n\nEpoch 00054: val_accuracy did not improve from 0.53333\nEpoch 55/70\n22/22 [==============================] - 4s 150ms/step - loss: 3.6846 - accuracy: 0.4486 - val_loss: 6.3238 - val_accuracy: 0.5300\n\nEpoch 00055: val_accuracy did not improve from 0.53333\nEpoch 56/70\n22/22 [==============================] - 4s 148ms/step - loss: 4.5053 - accuracy: 0.4800 - val_loss: 6.1257 - val_accuracy: 0.5367\n\nEpoch 00056: val_accuracy improved from 0.53333 to 0.53667, saving model to ./hyperparameter_adam_unfrozen.h5\nEpoch 57/70\n22/22 [==============================] - 4s 160ms/step - loss: 3.6271 - accuracy: 0.4714 - val_loss: 6.2768 - val_accuracy: 0.5167\n\nEpoch 00057: val_accuracy did not improve from 0.53667\nEpoch 58/70\n22/22 [==============================] - 4s 150ms/step - loss: 4.1214 - accuracy: 0.4443 - val_loss: 6.2673 - val_accuracy: 0.5067\n\nEpoch 00058: val_accuracy did not improve from 0.53667\nEpoch 59/70\n22/22 [==============================] - 4s 162ms/step - loss: 5.1623 - accuracy: 0.4557 - val_loss: 6.3340 - val_accuracy: 0.5200\n\nEpoch 00059: val_accuracy did not improve from 0.53667\nEpoch 60/70\n22/22 [==============================] - 4s 148ms/step - loss: 4.4556 - accuracy: 0.4900 - val_loss: 6.2288 - val_accuracy: 0.5333\n\nEpoch 00060: val_accuracy did not improve from 0.53667\nEpoch 61/70\n22/22 [==============================] - 4s 149ms/step - loss: 3.8961 - accuracy: 0.4400 - val_loss: 6.1763 - val_accuracy: 0.5367\n\nEpoch 00061: val_accuracy did not improve from 0.53667\nEpoch 62/70\n22/22 [==============================] - 4s 162ms/step - loss: 3.3395 - accuracy: 0.4671 - val_loss: 6.1256 - val_accuracy: 0.5400\n\nEpoch 00062: val_accuracy improved from 0.53667 to 0.54000, saving model to ./hyperparameter_adam_unfrozen.h5\nEpoch 63/70\n22/22 [==============================] - 4s 149ms/step - loss: 2.9743 - accuracy: 0.4457 - val_loss: 6.1781 - val_accuracy: 0.5333\n\nEpoch 00063: val_accuracy did not improve from 0.54000\nEpoch 64/70\n22/22 [==============================] - 4s 149ms/step - loss: 3.6867 - accuracy: 0.4471 - val_loss: 6.2830 - val_accuracy: 0.5400\n\nEpoch 00064: val_accuracy did not improve from 0.54000\nEpoch 65/70\n22/22 [==============================] - 4s 150ms/step - loss: 4.5895 - accuracy: 0.4671 - val_loss: 6.3540 - val_accuracy: 0.5333\n\nEpoch 00065: val_accuracy did not improve from 0.54000\nEpoch 66/70\n22/22 [==============================] - 4s 173ms/step - loss: 3.3421 - accuracy: 0.5114 - val_loss: 6.0957 - val_accuracy: 0.5367\n\nEpoch 00066: val_accuracy did not improve from 0.54000\nEpoch 67/70\n22/22 [==============================] - 4s 159ms/step - loss: 4.2346 - accuracy: 0.4643 - val_loss: 6.2859 - val_accuracy: 0.5267\n\nEpoch 00067: val_accuracy did not improve from 0.54000\nEpoch 68/70\n22/22 [==============================] - 4s 150ms/step - loss: 4.0540 - accuracy: 0.4557 - val_loss: 6.5144 - val_accuracy: 0.5000\n\nEpoch 00068: val_accuracy did not improve from 0.54000\nEpoch 69/70\n22/22 [==============================] - 4s 150ms/step - loss: 3.6437 - accuracy: 0.4714 - val_loss: 6.5446 - val_accuracy: 0.5400\n\nEpoch 00069: val_accuracy did not improve from 0.54000\nEpoch 70/70\n22/22 [==============================] - 4s 150ms/step - loss: 3.0669 - accuracy: 0.4543 - val_loss: 6.4508 - val_accuracy: 0.5500\n\nEpoch 00070: val_accuracy improved from 0.54000 to 0.55000, saving model to ./hyperparameter_adam_unfrozen.h5\n","output_type":"stream"}]},{"cell_type":"code","source":"adam_model_unfrozen = tf.keras.models.load_model(\"./hyperparameter_adam_unfrozen.h5\")\n\n\nadam_model_unfrozen.evaluate(test_dataset)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSqnwZkNPgjV","outputId":"82c9a88f-d557-4ebf-ec93-f71822d46934","execution":{"iopub.status.busy":"2022-11-10T22:34:19.097256Z","iopub.execute_input":"2022-11-10T22:34:19.097703Z","iopub.status.idle":"2022-11-10T22:34:25.225203Z","shell.execute_reply.started":"2022-11-10T22:34:19.097653Z","shell.execute_reply":"2022-11-10T22:34:25.224180Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 4s 4s/step - loss: 13.3998 - accuracy: 0.4667\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"[13.399843215942383, 0.46666666865348816]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Transfer Learning and tune the hyperparameters with some unfrozen layers (SGD optimizer)","metadata":{"id":"yHlMJnaKGHmA"}},{"cell_type":"code","source":"base_model.trainable = True","metadata":{"id":"7rw6dyAMAePu","execution":{"iopub.status.busy":"2022-11-10T22:34:32.995005Z","iopub.execute_input":"2022-11-10T22:34:32.995412Z","iopub.status.idle":"2022-11-10T22:34:33.001452Z","shell.execute_reply.started":"2022-11-10T22:34:32.995377Z","shell.execute_reply":"2022-11-10T22:34:33.000273Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"print(\"Number of layers in the base model: \", len(base_model.layers))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MpjCdRONBHFi","outputId":"da1d783b-d9c8-4620-ba50-324cc2035d95","execution":{"iopub.status.busy":"2022-11-10T22:34:34.282423Z","iopub.execute_input":"2022-11-10T22:34:34.283198Z","iopub.status.idle":"2022-11-10T22:34:34.289872Z","shell.execute_reply.started":"2022-11-10T22:34:34.283145Z","shell.execute_reply":"2022-11-10T22:34:34.287949Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Number of layers in the base model:  22\n","output_type":"stream"}]},{"cell_type":"code","source":"def model_builder_SGD_unfrozen(hp):\n    \n    hp_lr = hp.Choice('lr', [1e-2, 1e-3, 1e-4])\n    hp_layers = hp.Choice('layers', [2,4,6,8,10,12,14,16,18,20,22])\n\n    # Fine-tune from this layer onwards\n    fine_tune_at = hp_layers\n\n    # Freeze all the layers before the `fine_tune_at` layer\n    for layer in base_model.layers[:fine_tune_at]:\n      layer.trainable = False\n    \n    sgd_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= hp_lr),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\n    return sgd_model","metadata":{"id":"9AafS1vOBRmb","execution":{"iopub.status.busy":"2022-11-11T08:44:53.706584Z","iopub.execute_input":"2022-11-11T08:44:53.706973Z","iopub.status.idle":"2022-11-11T08:44:53.714430Z","shell.execute_reply.started":"2022-11-11T08:44:53.706939Z","shell.execute_reply":"2022-11-11T08:44:53.713067Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"tuner3 = kt.Hyperband(\n    model_builder_SGD_unfrozen,\n    objective='val_accuracy',\n    max_epochs=10,\n    directory=\"./\",\n    project_name='vgg_sgd_unfrozen'\n)\n\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\ntuner3.search(train_dataset, epochs=50,validation_data=validation_dataset, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner3.get_best_hyperparameters(num_trials=1)[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qc_eYF5EB4pH","outputId":"3441b69d-a65d-4923-ed07-c943611252da","execution":{"iopub.status.busy":"2022-11-10T22:42:41.920352Z","iopub.execute_input":"2022-11-10T22:42:41.920747Z","iopub.status.idle":"2022-11-10T22:48:11.904977Z","shell.execute_reply.started":"2022-11-10T22:42:41.920712Z","shell.execute_reply":"2022-11-10T22:48:11.903883Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Trial 30 Complete [00h 00m 29s]\nval_accuracy: 0.5766666531562805\n\nBest val_accuracy So Far: 0.7599999904632568\nTotal elapsed time: 00h 05m 29s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(best_hps.get('lr'))\nprint(best_hps.get('layers'))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"671QBq50HKXB","outputId":"ec995f67-2bb2-4629-bc78-95871a6186cb","execution":{"iopub.status.busy":"2022-11-10T22:48:56.290902Z","iopub.execute_input":"2022-11-10T22:48:56.291344Z","iopub.status.idle":"2022-11-10T22:48:56.298032Z","shell.execute_reply.started":"2022-11-10T22:48:56.291304Z","shell.execute_reply":"2022-11-10T22:48:56.296892Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"0.0001\n18\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model.trainable = True\nfine_tune_at = 18\n\n    # Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n    \nsgd_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate= 0.0001),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\n\nfine_tune_epochs = 20\ntotal_epochs =  50 + fine_tune_epochs\n\n\nmodel_checkpoints = [\n    tf.keras.callbacks.ModelCheckpoint(filepath = './hyperparameter_sgd_unfrozen.h5', \n    verbose=1, save_best_only=True, save_weights_only=False, mode='max', monitor='val_accuracy') \n    ]\n\nhistory_fine = sgd_model.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch=50,\n                         validation_data=validation_dataset,\n                             callbacks = [model_checkpoints])\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3FXbw5KbHRXM","outputId":"3117d046-c9f4-4690-fd80-20838507cbef","execution":{"iopub.status.busy":"2022-11-10T22:49:10.147438Z","iopub.execute_input":"2022-11-10T22:49:10.147825Z","iopub.status.idle":"2022-11-10T22:50:40.327042Z","shell.execute_reply.started":"2022-11-10T22:49:10.147793Z","shell.execute_reply":"2022-11-10T22:50:40.325711Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Epoch 51/70\n22/22 [==============================] - 5s 166ms/step - loss: 1.9145 - accuracy: 0.6900 - val_loss: 19.9133 - val_accuracy: 0.5533\n\nEpoch 00051: val_accuracy improved from -inf to 0.55333, saving model to ./hyperparameter_sgd_unfrozen.h5\nEpoch 52/70\n22/22 [==============================] - 4s 147ms/step - loss: 3.2794 - accuracy: 0.6900 - val_loss: 19.7806 - val_accuracy: 0.5533\n\nEpoch 00052: val_accuracy did not improve from 0.55333\nEpoch 53/70\n22/22 [==============================] - 4s 162ms/step - loss: 2.1960 - accuracy: 0.7014 - val_loss: 19.6774 - val_accuracy: 0.5533\n\nEpoch 00053: val_accuracy did not improve from 0.55333\nEpoch 54/70\n22/22 [==============================] - 4s 149ms/step - loss: 3.3699 - accuracy: 0.6829 - val_loss: 19.5679 - val_accuracy: 0.5533\n\nEpoch 00054: val_accuracy did not improve from 0.55333\nEpoch 55/70\n22/22 [==============================] - 4s 160ms/step - loss: 2.5240 - accuracy: 0.7171 - val_loss: 19.4484 - val_accuracy: 0.5533\n\nEpoch 00055: val_accuracy did not improve from 0.55333\nEpoch 56/70\n22/22 [==============================] - 4s 147ms/step - loss: 2.3525 - accuracy: 0.7071 - val_loss: 19.3507 - val_accuracy: 0.5533\n\nEpoch 00056: val_accuracy did not improve from 0.55333\nEpoch 57/70\n22/22 [==============================] - 4s 148ms/step - loss: 2.0813 - accuracy: 0.6871 - val_loss: 19.3525 - val_accuracy: 0.5533\n\nEpoch 00057: val_accuracy did not improve from 0.55333\nEpoch 58/70\n22/22 [==============================] - 4s 153ms/step - loss: 1.9425 - accuracy: 0.7086 - val_loss: 19.2810 - val_accuracy: 0.5533\n\nEpoch 00058: val_accuracy did not improve from 0.55333\nEpoch 59/70\n22/22 [==============================] - 4s 148ms/step - loss: 1.7153 - accuracy: 0.7186 - val_loss: 19.2266 - val_accuracy: 0.5533\n\nEpoch 00059: val_accuracy did not improve from 0.55333\nEpoch 60/70\n22/22 [==============================] - 4s 149ms/step - loss: 2.1259 - accuracy: 0.7000 - val_loss: 19.2036 - val_accuracy: 0.5533\n\nEpoch 00060: val_accuracy did not improve from 0.55333\nEpoch 61/70\n22/22 [==============================] - 4s 155ms/step - loss: 2.7449 - accuracy: 0.7100 - val_loss: 19.0814 - val_accuracy: 0.5533\n\nEpoch 00061: val_accuracy did not improve from 0.55333\nEpoch 62/70\n22/22 [==============================] - 4s 150ms/step - loss: 2.8080 - accuracy: 0.6700 - val_loss: 19.0506 - val_accuracy: 0.5533\n\nEpoch 00062: val_accuracy did not improve from 0.55333\nEpoch 63/70\n22/22 [==============================] - 4s 165ms/step - loss: 2.8036 - accuracy: 0.6971 - val_loss: 19.0071 - val_accuracy: 0.5533\n\nEpoch 00063: val_accuracy did not improve from 0.55333\nEpoch 64/70\n22/22 [==============================] - 4s 146ms/step - loss: 3.1038 - accuracy: 0.7171 - val_loss: 18.8874 - val_accuracy: 0.5533\n\nEpoch 00064: val_accuracy did not improve from 0.55333\nEpoch 65/70\n22/22 [==============================] - 4s 149ms/step - loss: 1.8604 - accuracy: 0.6986 - val_loss: 18.8184 - val_accuracy: 0.5533\n\nEpoch 00065: val_accuracy did not improve from 0.55333\nEpoch 66/70\n22/22 [==============================] - 4s 151ms/step - loss: 1.7277 - accuracy: 0.7057 - val_loss: 18.7802 - val_accuracy: 0.5533\n\nEpoch 00066: val_accuracy did not improve from 0.55333\nEpoch 67/70\n22/22 [==============================] - 4s 149ms/step - loss: 2.0341 - accuracy: 0.7014 - val_loss: 18.7436 - val_accuracy: 0.5533\n\nEpoch 00067: val_accuracy did not improve from 0.55333\nEpoch 68/70\n22/22 [==============================] - 4s 158ms/step - loss: 2.6268 - accuracy: 0.7057 - val_loss: 18.7045 - val_accuracy: 0.5533\n\nEpoch 00068: val_accuracy did not improve from 0.55333\nEpoch 69/70\n22/22 [==============================] - 4s 154ms/step - loss: 1.8040 - accuracy: 0.6929 - val_loss: 18.7027 - val_accuracy: 0.5533\n\nEpoch 00069: val_accuracy did not improve from 0.55333\nEpoch 70/70\n22/22 [==============================] - 4s 162ms/step - loss: 3.9282 - accuracy: 0.6771 - val_loss: 18.4874 - val_accuracy: 0.5533\n\nEpoch 00070: val_accuracy did not improve from 0.55333\n","output_type":"stream"}]},{"cell_type":"code","source":"sgd_model_unfrozen = tf.keras.models.load_model(\"hyperparameter_sgd_unfrozen.h5\")","metadata":{"id":"Qi4W6kFTKxeG","execution":{"iopub.status.busy":"2022-11-10T22:50:57.626261Z","iopub.execute_input":"2022-11-10T22:50:57.626665Z","iopub.status.idle":"2022-11-10T22:50:58.165273Z","shell.execute_reply.started":"2022-11-10T22:50:57.626631Z","shell.execute_reply":"2022-11-10T22:50:58.164245Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"sgd_model_unfrozen.evaluate(test_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5U_q0vn1K1s_","outputId":"f9363417-c05a-4fa1-c5e2-9fc486c2b733","execution":{"iopub.status.busy":"2022-11-10T22:50:59.952167Z","iopub.execute_input":"2022-11-10T22:50:59.953388Z","iopub.status.idle":"2022-11-10T22:51:03.956239Z","shell.execute_reply.started":"2022-11-10T22:50:59.953338Z","shell.execute_reply":"2022-11-10T22:51:03.955224Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 4s 4s/step - loss: 20.3343 - accuracy: 0.4667\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"[20.3343448638916, 0.46666666865348816]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Add more training images by generating more images using GAN","metadata":{}},{"cell_type":"code","source":"materials = ['fabric','foliage','glass','leather','metal','paper','plastic','stone','water','wood']\n\npath_to_folder = '../input/ganmaterials/cz4042_neural_networks_deep_learning-main/data/image'\n\ntrain_dataset_GAN = tf.keras.utils.image_dataset_from_directory(\n    directory=path_to_folder,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=materials,\n    # color_mode='grayscale',\n    batch_size=32,\n    image_size=(224,224),\n    shuffle=True,\n    seed=42,\n    validation_split=0.3,\n    subset='training')\n    \n    \nvalidation_dataset_GAN = tf.keras.utils.image_dataset_from_directory(\n    directory=path_to_folder,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=materials,\n    # color_mode='grayscale',\n    batch_size=32,\n    image_size=(224,224),\n    shuffle=True,\n    seed=42,\n    validation_split=0.3,\n    subset='validation')\n","metadata":{"execution":{"iopub.status.busy":"2022-11-11T07:29:42.585034Z","iopub.execute_input":"2022-11-11T07:29:42.585440Z","iopub.status.idle":"2022-11-11T07:29:42.977353Z","shell.execute_reply.started":"2022-11-11T07:29:42.585383Z","shell.execute_reply":"2022-11-11T07:29:42.976258Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 2000 files belonging to 10 classes.\nUsing 1400 files for training.\nFound 2000 files belonging to 10 classes.\nUsing 600 files for validation.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Transfer Learning and tune the hyperparameters with frozen layers with GAN (Adam optimizer)","metadata":{}},{"cell_type":"code","source":"tuner = kt.Hyperband(\n    model_builder,\n    objective='val_accuracy',\n    max_epochs=10,\n    directory=\"./\",\n    project_name = \"adam_GAN\"\n)\n\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\ntuner.search(train_dataset_GAN, epochs=50,validation_data=validation_dataset_GAN, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n\nprint(best_hps.get('units'))\nprint(best_hps.get('lr'))\nprint(best_hps.get('ratio1'))\nprint(best_hps.get('ratio2'))\nprint(best_hps.get('activation'))","metadata":{"execution":{"iopub.status.busy":"2022-11-11T07:34:34.451246Z","iopub.execute_input":"2022-11-11T07:34:34.451944Z","iopub.status.idle":"2022-11-11T07:51:32.755821Z","shell.execute_reply.started":"2022-11-11T07:34:34.451907Z","shell.execute_reply":"2022-11-11T07:51:32.754743Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Trial 30 Complete [00h 01m 19s]\nval_accuracy: 0.1899999976158142\n\nBest val_accuracy So Far: 0.7099999785423279\nTotal elapsed time: 00h 16m 58s\n512\n0.0001\n0.1\n0.7\nelu\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(224, 224, 3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = Flatten()(x)\nx = tf.keras.layers.Dropout(0.1)(x)\nx = tf.keras.layers.Dense(units=512, activation='elu')(x)\nx = tf.keras.layers.Dropout(0.7)(x)\nprediction = Dense(10, activation='softmax')(x)\nmodel = tf.keras.Model(inputs=inputs, outputs=prediction)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 0.0001),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\nmodel_checkpoints = [\n    tf.keras.callbacks.ModelCheckpoint(filepath = 'hyperparameter_adam_GAN.h5', \n    verbose=1, save_best_only=True, save_weights_only=False, mode='max', monitor='val_accuracy') \n    ]\n\nhistory = model.fit(train_dataset_GAN, epochs=50, validation_data = validation_dataset_GAN, callbacks = [model_checkpoints])\n","metadata":{"execution":{"iopub.status.busy":"2022-11-11T07:57:30.689987Z","iopub.execute_input":"2022-11-11T07:57:30.690712Z","iopub.status.idle":"2022-11-11T08:04:28.060659Z","shell.execute_reply.started":"2022-11-11T07:57:30.690667Z","shell.execute_reply":"2022-11-11T08:04:28.059451Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/50\n44/44 [==============================] - 7s 135ms/step - loss: 17.2776 - accuracy: 0.2736 - val_loss: 5.1677 - val_accuracy: 0.5783\n\nEpoch 00001: val_accuracy improved from -inf to 0.57833, saving model to hyperparameter_adam_GAN.h5\nEpoch 2/50\n44/44 [==============================] - 6s 131ms/step - loss: 6.1738 - accuracy: 0.4921 - val_loss: 2.6813 - val_accuracy: 0.6533\n\nEpoch 00002: val_accuracy improved from 0.57833 to 0.65333, saving model to hyperparameter_adam_GAN.h5\nEpoch 3/50\n44/44 [==============================] - 7s 136ms/step - loss: 4.0245 - accuracy: 0.5421 - val_loss: 1.9307 - val_accuracy: 0.6617\n\nEpoch 00003: val_accuracy improved from 0.65333 to 0.66167, saving model to hyperparameter_adam_GAN.h5\nEpoch 4/50\n44/44 [==============================] - 6s 133ms/step - loss: 3.5096 - accuracy: 0.5329 - val_loss: 1.7263 - val_accuracy: 0.6850\n\nEpoch 00004: val_accuracy improved from 0.66167 to 0.68500, saving model to hyperparameter_adam_GAN.h5\nEpoch 5/50\n44/44 [==============================] - 6s 128ms/step - loss: 2.6559 - accuracy: 0.5871 - val_loss: 1.3867 - val_accuracy: 0.7000\n\nEpoch 00005: val_accuracy improved from 0.68500 to 0.70000, saving model to hyperparameter_adam_GAN.h5\nEpoch 6/50\n44/44 [==============================] - 6s 130ms/step - loss: 2.3927 - accuracy: 0.6029 - val_loss: 1.3127 - val_accuracy: 0.7117\n\nEpoch 00006: val_accuracy improved from 0.70000 to 0.71167, saving model to hyperparameter_adam_GAN.h5\nEpoch 7/50\n44/44 [==============================] - 6s 140ms/step - loss: 2.1663 - accuracy: 0.6000 - val_loss: 1.4160 - val_accuracy: 0.7033\n\nEpoch 00007: val_accuracy did not improve from 0.71167\nEpoch 8/50\n44/44 [==============================] - 7s 136ms/step - loss: 1.9790 - accuracy: 0.6307 - val_loss: 1.2156 - val_accuracy: 0.7517\n\nEpoch 00008: val_accuracy improved from 0.71167 to 0.75167, saving model to hyperparameter_adam_GAN.h5\nEpoch 9/50\n44/44 [==============================] - 6s 131ms/step - loss: 2.0545 - accuracy: 0.6250 - val_loss: 1.0862 - val_accuracy: 0.7567\n\nEpoch 00009: val_accuracy improved from 0.75167 to 0.75667, saving model to hyperparameter_adam_GAN.h5\nEpoch 10/50\n44/44 [==============================] - 6s 130ms/step - loss: 1.8796 - accuracy: 0.6343 - val_loss: 1.1687 - val_accuracy: 0.7683\n\nEpoch 00010: val_accuracy improved from 0.75667 to 0.76833, saving model to hyperparameter_adam_GAN.h5\nEpoch 11/50\n44/44 [==============================] - 7s 140ms/step - loss: 1.5908 - accuracy: 0.6800 - val_loss: 1.0571 - val_accuracy: 0.7800\n\nEpoch 00011: val_accuracy improved from 0.76833 to 0.78000, saving model to hyperparameter_adam_GAN.h5\nEpoch 12/50\n44/44 [==============================] - 6s 132ms/step - loss: 1.6061 - accuracy: 0.6921 - val_loss: 1.0262 - val_accuracy: 0.7767\n\nEpoch 00012: val_accuracy did not improve from 0.78000\nEpoch 13/50\n44/44 [==============================] - 6s 128ms/step - loss: 1.5398 - accuracy: 0.6993 - val_loss: 0.9586 - val_accuracy: 0.7933\n\nEpoch 00013: val_accuracy improved from 0.78000 to 0.79333, saving model to hyperparameter_adam_GAN.h5\nEpoch 14/50\n44/44 [==============================] - 6s 129ms/step - loss: 1.3549 - accuracy: 0.7279 - val_loss: 1.1318 - val_accuracy: 0.7817\n\nEpoch 00014: val_accuracy did not improve from 0.79333\nEpoch 15/50\n44/44 [==============================] - 6s 132ms/step - loss: 1.3787 - accuracy: 0.7150 - val_loss: 1.1909 - val_accuracy: 0.7900\n\nEpoch 00015: val_accuracy did not improve from 0.79333\nEpoch 16/50\n44/44 [==============================] - 6s 129ms/step - loss: 1.3145 - accuracy: 0.7414 - val_loss: 0.9641 - val_accuracy: 0.8033\n\nEpoch 00016: val_accuracy improved from 0.79333 to 0.80333, saving model to hyperparameter_adam_GAN.h5\nEpoch 17/50\n44/44 [==============================] - 6s 129ms/step - loss: 1.2560 - accuracy: 0.7486 - val_loss: 1.0681 - val_accuracy: 0.8033\n\nEpoch 00017: val_accuracy did not improve from 0.80333\nEpoch 18/50\n44/44 [==============================] - 6s 131ms/step - loss: 1.1533 - accuracy: 0.7664 - val_loss: 1.1406 - val_accuracy: 0.8000\n\nEpoch 00018: val_accuracy did not improve from 0.80333\nEpoch 19/50\n44/44 [==============================] - 6s 130ms/step - loss: 1.0596 - accuracy: 0.7771 - val_loss: 1.2004 - val_accuracy: 0.8083\n\nEpoch 00019: val_accuracy improved from 0.80333 to 0.80833, saving model to hyperparameter_adam_GAN.h5\nEpoch 20/50\n44/44 [==============================] - 6s 130ms/step - loss: 1.0588 - accuracy: 0.7686 - val_loss: 1.1461 - val_accuracy: 0.8067\n\nEpoch 00020: val_accuracy did not improve from 0.80833\nEpoch 21/50\n44/44 [==============================] - 6s 128ms/step - loss: 1.0917 - accuracy: 0.7993 - val_loss: 1.1736 - val_accuracy: 0.7983\n\nEpoch 00021: val_accuracy did not improve from 0.80833\nEpoch 22/50\n44/44 [==============================] - 6s 132ms/step - loss: 1.0511 - accuracy: 0.7921 - val_loss: 1.1974 - val_accuracy: 0.8133\n\nEpoch 00022: val_accuracy improved from 0.80833 to 0.81333, saving model to hyperparameter_adam_GAN.h5\nEpoch 23/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.9827 - accuracy: 0.8029 - val_loss: 1.1827 - val_accuracy: 0.8133\n\nEpoch 00023: val_accuracy did not improve from 0.81333\nEpoch 24/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.8514 - accuracy: 0.8107 - val_loss: 1.1962 - val_accuracy: 0.8250\n\nEpoch 00024: val_accuracy improved from 0.81333 to 0.82500, saving model to hyperparameter_adam_GAN.h5\nEpoch 25/50\n44/44 [==============================] - 7s 155ms/step - loss: 0.8637 - accuracy: 0.8129 - val_loss: 1.2099 - val_accuracy: 0.8183\n\nEpoch 00025: val_accuracy did not improve from 0.82500\nEpoch 26/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.9148 - accuracy: 0.8086 - val_loss: 1.2141 - val_accuracy: 0.8217\n\nEpoch 00026: val_accuracy did not improve from 0.82500\nEpoch 27/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.7940 - accuracy: 0.8357 - val_loss: 1.1266 - val_accuracy: 0.8267\n\nEpoch 00027: val_accuracy improved from 0.82500 to 0.82667, saving model to hyperparameter_adam_GAN.h5\nEpoch 28/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.8268 - accuracy: 0.8286 - val_loss: 1.1439 - val_accuracy: 0.8350\n\nEpoch 00028: val_accuracy improved from 0.82667 to 0.83500, saving model to hyperparameter_adam_GAN.h5\nEpoch 29/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.8984 - accuracy: 0.8150 - val_loss: 1.1696 - val_accuracy: 0.8383\n\nEpoch 00029: val_accuracy improved from 0.83500 to 0.83833, saving model to hyperparameter_adam_GAN.h5\nEpoch 30/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.6642 - accuracy: 0.8550 - val_loss: 1.0799 - val_accuracy: 0.8533\n\nEpoch 00030: val_accuracy improved from 0.83833 to 0.85333, saving model to hyperparameter_adam_GAN.h5\nEpoch 31/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.8063 - accuracy: 0.8486 - val_loss: 1.1546 - val_accuracy: 0.8433\n\nEpoch 00031: val_accuracy did not improve from 0.85333\nEpoch 32/50\n44/44 [==============================] - 6s 128ms/step - loss: 0.8091 - accuracy: 0.8479 - val_loss: 1.1637 - val_accuracy: 0.8333\n\nEpoch 00032: val_accuracy did not improve from 0.85333\nEpoch 33/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.7203 - accuracy: 0.8429 - val_loss: 1.0661 - val_accuracy: 0.8433\n\nEpoch 00033: val_accuracy did not improve from 0.85333\nEpoch 34/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.5864 - accuracy: 0.8593 - val_loss: 1.0880 - val_accuracy: 0.8533\n\nEpoch 00034: val_accuracy did not improve from 0.85333\nEpoch 35/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.7127 - accuracy: 0.8443 - val_loss: 1.1090 - val_accuracy: 0.8233\n\nEpoch 00035: val_accuracy did not improve from 0.85333\nEpoch 36/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.7103 - accuracy: 0.8564 - val_loss: 1.1525 - val_accuracy: 0.8283\n\nEpoch 00036: val_accuracy did not improve from 0.85333\nEpoch 37/50\n44/44 [==============================] - 6s 133ms/step - loss: 0.6607 - accuracy: 0.8543 - val_loss: 1.2060 - val_accuracy: 0.8383\n\nEpoch 00037: val_accuracy did not improve from 0.85333\nEpoch 38/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.7084 - accuracy: 0.8543 - val_loss: 1.1071 - val_accuracy: 0.8450\n\nEpoch 00038: val_accuracy did not improve from 0.85333\nEpoch 39/50\n44/44 [==============================] - 6s 134ms/step - loss: 0.7095 - accuracy: 0.8514 - val_loss: 1.1584 - val_accuracy: 0.8450\n\nEpoch 00039: val_accuracy did not improve from 0.85333\nEpoch 40/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.6794 - accuracy: 0.8700 - val_loss: 1.1267 - val_accuracy: 0.8550\n\nEpoch 00040: val_accuracy improved from 0.85333 to 0.85500, saving model to hyperparameter_adam_GAN.h5\nEpoch 41/50\n44/44 [==============================] - 6s 128ms/step - loss: 0.5635 - accuracy: 0.8764 - val_loss: 1.0553 - val_accuracy: 0.8467\n\nEpoch 00041: val_accuracy did not improve from 0.85500\nEpoch 42/50\n44/44 [==============================] - 6s 134ms/step - loss: 0.5621 - accuracy: 0.8843 - val_loss: 1.0746 - val_accuracy: 0.8483\n\nEpoch 00042: val_accuracy did not improve from 0.85500\nEpoch 43/50\n44/44 [==============================] - 6s 133ms/step - loss: 0.5172 - accuracy: 0.8864 - val_loss: 1.1393 - val_accuracy: 0.8467\n\nEpoch 00043: val_accuracy did not improve from 0.85500\nEpoch 44/50\n44/44 [==============================] - 6s 132ms/step - loss: 0.5130 - accuracy: 0.8821 - val_loss: 1.1612 - val_accuracy: 0.8500\n\nEpoch 00044: val_accuracy did not improve from 0.85500\nEpoch 45/50\n44/44 [==============================] - 6s 128ms/step - loss: 0.5721 - accuracy: 0.8829 - val_loss: 1.2359 - val_accuracy: 0.8483\n\nEpoch 00045: val_accuracy did not improve from 0.85500\nEpoch 46/50\n44/44 [==============================] - 6s 133ms/step - loss: 0.5120 - accuracy: 0.8964 - val_loss: 1.1078 - val_accuracy: 0.8650\n\nEpoch 00046: val_accuracy improved from 0.85500 to 0.86500, saving model to hyperparameter_adam_GAN.h5\nEpoch 47/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.4980 - accuracy: 0.8929 - val_loss: 1.1702 - val_accuracy: 0.8567\n\nEpoch 00047: val_accuracy did not improve from 0.86500\nEpoch 48/50\n44/44 [==============================] - 6s 133ms/step - loss: 0.5386 - accuracy: 0.8914 - val_loss: 1.1450 - val_accuracy: 0.8550\n\nEpoch 00048: val_accuracy did not improve from 0.86500\nEpoch 49/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.4513 - accuracy: 0.8900 - val_loss: 1.2398 - val_accuracy: 0.8550\n\nEpoch 00049: val_accuracy did not improve from 0.86500\nEpoch 50/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.4868 - accuracy: 0.9021 - val_loss: 1.2630 - val_accuracy: 0.8517\n\nEpoch 00050: val_accuracy did not improve from 0.86500\n","output_type":"stream"}]},{"cell_type":"code","source":"adam_model_GAN = tf.keras.models.load_model(\"./hyperparameter_adam_GAN.h5\")\nadam_model_GAN.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-11-11T08:07:10.113852Z","iopub.execute_input":"2022-11-11T08:07:10.114284Z","iopub.status.idle":"2022-11-11T08:07:18.537520Z","shell.execute_reply.started":"2022-11-11T08:07:10.114246Z","shell.execute_reply":"2022-11-11T08:07:18.536302Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 8s 8s/step - loss: 2.1804 - accuracy: 0.7000\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[2.180387020111084, 0.699999988079071]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Transfer Learning and tune the hyperparameters with frozen layers with GAN (SGD optimizer)","metadata":{}},{"cell_type":"code","source":"tuner2 = kt.Hyperband(\n    model_builder_SGD,\n    objective='val_accuracy',\n    max_epochs=10,\n    directory=\"./\",\n    project_name='sgd_GAN'\n)\n\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\ntuner2.search(train_dataset_GAN, epochs=50,validation_data=validation_dataset_GAN, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner2.get_best_hyperparameters(num_trials=1)[0]\n\nprint(best_hps.get('units'))\nprint(best_hps.get('lr'))\nprint(best_hps.get('ratio1'))\nprint(best_hps.get('ratio2'))\nprint(best_hps.get('activation'))","metadata":{"execution":{"iopub.status.busy":"2022-11-11T08:10:27.139251Z","iopub.execute_input":"2022-11-11T08:10:27.139950Z","iopub.status.idle":"2022-11-11T08:29:07.166569Z","shell.execute_reply.started":"2022-11-11T08:10:27.139914Z","shell.execute_reply":"2022-11-11T08:29:07.165468Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Trial 30 Complete [00h 01m 27s]\nval_accuracy: 0.7683333158493042\n\nBest val_accuracy So Far: 0.7799999713897705\nTotal elapsed time: 00h 18m 39s\n1024\n0.001\n0.3\n0.5\nrelu\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(224, 224, 3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = Flatten()(x)\nx = tf.keras.layers.Dropout(0.3)(x)\nx = tf.keras.layers.Dense(units=1024, activation='elu')(x)\nx = tf.keras.layers.Dropout(0.5)(x)\nprediction = Dense(10, activation='softmax')(x)\nmodel = tf.keras.Model(inputs=inputs, outputs=prediction)\n\nmodel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate= 0.001),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\nmodel_checkpoints = [\n    tf.keras.callbacks.ModelCheckpoint(filepath = 'hyperparameter_SGD_GAN.h5', \n    verbose=1, save_best_only=True, save_weights_only=False, mode='max', monitor='val_accuracy') \n    ]\n\nhistory = model.fit(train_dataset_GAN, epochs=50, validation_data = validation_dataset_GAN, callbacks = [model_checkpoints])\n","metadata":{"execution":{"iopub.status.busy":"2022-11-11T08:30:47.787137Z","iopub.execute_input":"2022-11-11T08:30:47.787519Z","iopub.status.idle":"2022-11-11T08:37:56.850967Z","shell.execute_reply.started":"2022-11-11T08:30:47.787487Z","shell.execute_reply":"2022-11-11T08:37:56.850050Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/50\n44/44 [==============================] - 7s 137ms/step - loss: 13.1082 - accuracy: 0.3793 - val_loss: 4.9996 - val_accuracy: 0.6433\n\nEpoch 00001: val_accuracy improved from -inf to 0.64333, saving model to hyperparameter_SGD_GAN.h5\nEpoch 2/50\n44/44 [==============================] - 6s 130ms/step - loss: 6.3044 - accuracy: 0.5857 - val_loss: 3.8974 - val_accuracy: 0.6900\n\nEpoch 00002: val_accuracy improved from 0.64333 to 0.69000, saving model to hyperparameter_SGD_GAN.h5\nEpoch 3/50\n44/44 [==============================] - 6s 132ms/step - loss: 4.4720 - accuracy: 0.6414 - val_loss: 3.1193 - val_accuracy: 0.7167\n\nEpoch 00003: val_accuracy improved from 0.69000 to 0.71667, saving model to hyperparameter_SGD_GAN.h5\nEpoch 4/50\n44/44 [==============================] - 6s 132ms/step - loss: 3.5877 - accuracy: 0.6843 - val_loss: 2.4248 - val_accuracy: 0.7350\n\nEpoch 00004: val_accuracy improved from 0.71667 to 0.73500, saving model to hyperparameter_SGD_GAN.h5\nEpoch 5/50\n44/44 [==============================] - 6s 130ms/step - loss: 2.5290 - accuracy: 0.7157 - val_loss: 2.1665 - val_accuracy: 0.7617\n\nEpoch 00005: val_accuracy improved from 0.73500 to 0.76167, saving model to hyperparameter_SGD_GAN.h5\nEpoch 6/50\n44/44 [==============================] - 7s 130ms/step - loss: 2.1579 - accuracy: 0.7550 - val_loss: 2.0552 - val_accuracy: 0.7617\n\nEpoch 00006: val_accuracy did not improve from 0.76167\nEpoch 7/50\n44/44 [==============================] - 6s 139ms/step - loss: 1.9018 - accuracy: 0.7471 - val_loss: 1.9352 - val_accuracy: 0.7700\n\nEpoch 00007: val_accuracy improved from 0.76167 to 0.77000, saving model to hyperparameter_SGD_GAN.h5\nEpoch 8/50\n44/44 [==============================] - 6s 133ms/step - loss: 1.5427 - accuracy: 0.7836 - val_loss: 1.8929 - val_accuracy: 0.7783\n\nEpoch 00008: val_accuracy improved from 0.77000 to 0.77833, saving model to hyperparameter_SGD_GAN.h5\nEpoch 9/50\n44/44 [==============================] - 6s 130ms/step - loss: 1.4175 - accuracy: 0.7993 - val_loss: 1.5856 - val_accuracy: 0.7950\n\nEpoch 00009: val_accuracy improved from 0.77833 to 0.79500, saving model to hyperparameter_SGD_GAN.h5\nEpoch 10/50\n44/44 [==============================] - 6s 129ms/step - loss: 1.1444 - accuracy: 0.8314 - val_loss: 1.5157 - val_accuracy: 0.7967\n\nEpoch 00010: val_accuracy improved from 0.79500 to 0.79667, saving model to hyperparameter_SGD_GAN.h5\nEpoch 11/50\n44/44 [==============================] - 6s 132ms/step - loss: 1.3944 - accuracy: 0.8121 - val_loss: 1.5403 - val_accuracy: 0.8100\n\nEpoch 00011: val_accuracy improved from 0.79667 to 0.81000, saving model to hyperparameter_SGD_GAN.h5\nEpoch 12/50\n44/44 [==============================] - 6s 130ms/step - loss: 1.0211 - accuracy: 0.8371 - val_loss: 1.4377 - val_accuracy: 0.8100\n\nEpoch 00012: val_accuracy did not improve from 0.81000\nEpoch 13/50\n44/44 [==============================] - 6s 132ms/step - loss: 0.8900 - accuracy: 0.8364 - val_loss: 1.3795 - val_accuracy: 0.7933\n\nEpoch 00013: val_accuracy did not improve from 0.81000\nEpoch 14/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.9590 - accuracy: 0.8293 - val_loss: 1.3193 - val_accuracy: 0.8250\n\nEpoch 00014: val_accuracy improved from 0.81000 to 0.82500, saving model to hyperparameter_SGD_GAN.h5\nEpoch 15/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.7296 - accuracy: 0.8636 - val_loss: 1.3636 - val_accuracy: 0.8100\n\nEpoch 00015: val_accuracy did not improve from 0.82500\nEpoch 16/50\n44/44 [==============================] - 8s 172ms/step - loss: 0.6944 - accuracy: 0.8629 - val_loss: 1.2499 - val_accuracy: 0.8167\n\nEpoch 00016: val_accuracy did not improve from 0.82500\nEpoch 17/50\n44/44 [==============================] - 6s 133ms/step - loss: 0.7873 - accuracy: 0.8536 - val_loss: 1.1910 - val_accuracy: 0.8233\n\nEpoch 00017: val_accuracy did not improve from 0.82500\nEpoch 18/50\n44/44 [==============================] - 6s 135ms/step - loss: 0.6863 - accuracy: 0.8621 - val_loss: 1.2653 - val_accuracy: 0.8133\n\nEpoch 00018: val_accuracy did not improve from 0.82500\nEpoch 19/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.6047 - accuracy: 0.8736 - val_loss: 1.2279 - val_accuracy: 0.8300\n\nEpoch 00019: val_accuracy improved from 0.82500 to 0.83000, saving model to hyperparameter_SGD_GAN.h5\nEpoch 20/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.6996 - accuracy: 0.8614 - val_loss: 1.1816 - val_accuracy: 0.8383\n\nEpoch 00020: val_accuracy improved from 0.83000 to 0.83833, saving model to hyperparameter_SGD_GAN.h5\nEpoch 21/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.5775 - accuracy: 0.8871 - val_loss: 1.1465 - val_accuracy: 0.8350\n\nEpoch 00021: val_accuracy did not improve from 0.83833\nEpoch 22/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.5614 - accuracy: 0.8764 - val_loss: 1.1729 - val_accuracy: 0.8300\n\nEpoch 00022: val_accuracy did not improve from 0.83833\nEpoch 23/50\n44/44 [==============================] - 6s 135ms/step - loss: 0.5347 - accuracy: 0.8864 - val_loss: 1.1447 - val_accuracy: 0.8367\n\nEpoch 00023: val_accuracy did not improve from 0.83833\nEpoch 24/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.5506 - accuracy: 0.8821 - val_loss: 1.0512 - val_accuracy: 0.8450\n\nEpoch 00024: val_accuracy improved from 0.83833 to 0.84500, saving model to hyperparameter_SGD_GAN.h5\nEpoch 25/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.4750 - accuracy: 0.8936 - val_loss: 1.1076 - val_accuracy: 0.8383\n\nEpoch 00025: val_accuracy did not improve from 0.84500\nEpoch 26/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.5247 - accuracy: 0.8857 - val_loss: 1.0888 - val_accuracy: 0.8417\n\nEpoch 00026: val_accuracy did not improve from 0.84500\nEpoch 27/50\n44/44 [==============================] - 7s 143ms/step - loss: 0.4711 - accuracy: 0.8893 - val_loss: 1.1405 - val_accuracy: 0.8383\n\nEpoch 00027: val_accuracy did not improve from 0.84500\nEpoch 28/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.4604 - accuracy: 0.9093 - val_loss: 1.0740 - val_accuracy: 0.8483\n\nEpoch 00028: val_accuracy improved from 0.84500 to 0.84833, saving model to hyperparameter_SGD_GAN.h5\nEpoch 29/50\n44/44 [==============================] - 6s 133ms/step - loss: 0.4796 - accuracy: 0.9000 - val_loss: 1.0597 - val_accuracy: 0.8417\n\nEpoch 00029: val_accuracy did not improve from 0.84833\nEpoch 30/50\n44/44 [==============================] - 6s 135ms/step - loss: 0.4528 - accuracy: 0.9007 - val_loss: 1.0560 - val_accuracy: 0.8383\n\nEpoch 00030: val_accuracy did not improve from 0.84833\nEpoch 31/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.2852 - accuracy: 0.9264 - val_loss: 1.0550 - val_accuracy: 0.8483\n\nEpoch 00031: val_accuracy did not improve from 0.84833\nEpoch 32/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.4001 - accuracy: 0.9079 - val_loss: 1.0222 - val_accuracy: 0.8517\n\nEpoch 00032: val_accuracy improved from 0.84833 to 0.85167, saving model to hyperparameter_SGD_GAN.h5\nEpoch 33/50\n44/44 [==============================] - 6s 132ms/step - loss: 0.3848 - accuracy: 0.9071 - val_loss: 0.9756 - val_accuracy: 0.8583\n\nEpoch 00033: val_accuracy improved from 0.85167 to 0.85833, saving model to hyperparameter_SGD_GAN.h5\nEpoch 34/50\n44/44 [==============================] - 6s 135ms/step - loss: 0.3369 - accuracy: 0.9214 - val_loss: 0.9837 - val_accuracy: 0.8600\n\nEpoch 00034: val_accuracy improved from 0.85833 to 0.86000, saving model to hyperparameter_SGD_GAN.h5\nEpoch 35/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.3584 - accuracy: 0.9193 - val_loss: 0.9466 - val_accuracy: 0.8583\n\nEpoch 00035: val_accuracy did not improve from 0.86000\nEpoch 36/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.3423 - accuracy: 0.9164 - val_loss: 0.9840 - val_accuracy: 0.8583\n\nEpoch 00036: val_accuracy did not improve from 0.86000\nEpoch 37/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.3008 - accuracy: 0.9179 - val_loss: 0.9214 - val_accuracy: 0.8633\n\nEpoch 00037: val_accuracy improved from 0.86000 to 0.86333, saving model to hyperparameter_SGD_GAN.h5\nEpoch 38/50\n44/44 [==============================] - 6s 134ms/step - loss: 0.4120 - accuracy: 0.9157 - val_loss: 0.9308 - val_accuracy: 0.8600\n\nEpoch 00038: val_accuracy did not improve from 0.86333\nEpoch 39/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.2637 - accuracy: 0.9264 - val_loss: 0.9425 - val_accuracy: 0.8617\n\nEpoch 00039: val_accuracy did not improve from 0.86333\nEpoch 40/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.3371 - accuracy: 0.9186 - val_loss: 0.9431 - val_accuracy: 0.8700\n\nEpoch 00040: val_accuracy improved from 0.86333 to 0.87000, saving model to hyperparameter_SGD_GAN.h5\nEpoch 41/50\n44/44 [==============================] - 6s 137ms/step - loss: 0.2871 - accuracy: 0.9271 - val_loss: 0.9919 - val_accuracy: 0.8650\n\nEpoch 00041: val_accuracy did not improve from 0.87000\nEpoch 42/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.2432 - accuracy: 0.9364 - val_loss: 1.0147 - val_accuracy: 0.8683\n\nEpoch 00042: val_accuracy did not improve from 0.87000\nEpoch 43/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.2919 - accuracy: 0.9293 - val_loss: 1.0446 - val_accuracy: 0.8550\n\nEpoch 00043: val_accuracy did not improve from 0.87000\nEpoch 44/50\n44/44 [==============================] - 7s 145ms/step - loss: 0.2447 - accuracy: 0.9350 - val_loss: 1.0635 - val_accuracy: 0.8517\n\nEpoch 00044: val_accuracy did not improve from 0.87000\nEpoch 45/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.2965 - accuracy: 0.9336 - val_loss: 0.9571 - val_accuracy: 0.8800\n\nEpoch 00045: val_accuracy improved from 0.87000 to 0.88000, saving model to hyperparameter_SGD_GAN.h5\nEpoch 46/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.3077 - accuracy: 0.9229 - val_loss: 0.9632 - val_accuracy: 0.8733\n\nEpoch 00046: val_accuracy did not improve from 0.88000\nEpoch 47/50\n44/44 [==============================] - 6s 130ms/step - loss: 0.2827 - accuracy: 0.9343 - val_loss: 0.9540 - val_accuracy: 0.8767\n\nEpoch 00047: val_accuracy did not improve from 0.88000\nEpoch 48/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.2566 - accuracy: 0.9343 - val_loss: 0.9613 - val_accuracy: 0.8750\n\nEpoch 00048: val_accuracy did not improve from 0.88000\nEpoch 49/50\n44/44 [==============================] - 6s 129ms/step - loss: 0.2542 - accuracy: 0.9336 - val_loss: 0.9584 - val_accuracy: 0.8700\n\nEpoch 00049: val_accuracy did not improve from 0.88000\nEpoch 50/50\n44/44 [==============================] - 6s 131ms/step - loss: 0.2223 - accuracy: 0.9429 - val_loss: 0.9589 - val_accuracy: 0.8750\n\nEpoch 00050: val_accuracy did not improve from 0.88000\n","output_type":"stream"}]},{"cell_type":"code","source":"sgd_model_GAN = tf.keras.models.load_model(\"./hyperparameter_SGD_GAN.h5\")\nsgd_model_GAN.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-11-11T08:43:28.668340Z","iopub.execute_input":"2022-11-11T08:43:28.669042Z","iopub.status.idle":"2022-11-11T08:43:33.730059Z","shell.execute_reply.started":"2022-11-11T08:43:28.669008Z","shell.execute_reply":"2022-11-11T08:43:33.729006Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 4s 4s/step - loss: 1.4135 - accuracy: 0.7000\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[1.4134563207626343, 0.699999988079071]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Transfer Learning and tune the hyperparameters with some unfrozen layers with GAN (Adam optimizer)","metadata":{}},{"cell_type":"code","source":"base_model.trainable = True\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\ndef model_builder_Adam_unfrozen_GAN(hp):\n    \n    hp_lr = hp.Choice('lr', [1e-2, 1e-3, 1e-4])\n    hp_layers = hp.Choice('layers', [2,4,6,8,10,12,14,16,18,20,22])\n\n    # Fine-tune from this layer onwards\n    fine_tune_at = hp_layers\n\n    # Freeze all the layers before the `fine_tune_at` layer\n    for layer in base_model.layers[:fine_tune_at]:\n      layer.trainable = False\n    \n    adam_model_GAN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= hp_lr),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\n    return adam_model_GAN\n\ntuner4 = kt.Hyperband(\n    model_builder_Adam_unfrozen_GAN,\n    objective='val_accuracy',\n    max_epochs=10,\n    directory=\"./\",\n    project_name='adam_unfrozen_GAN'\n)\n\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\ntuner4.search(train_dataset_GAN, epochs=50,validation_data=validation_dataset_GAN, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner4.get_best_hyperparameters(num_trials=1)[0]","metadata":{"execution":{"iopub.status.busy":"2022-11-11T08:48:16.536297Z","iopub.execute_input":"2022-11-11T08:48:16.536999Z","iopub.status.idle":"2022-11-11T09:04:52.735851Z","shell.execute_reply.started":"2022-11-11T08:48:16.536964Z","shell.execute_reply":"2022-11-11T09:04:52.733448Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Trial 30 Complete [00h 01m 28s]\nval_accuracy: 0.2016666680574417\n\nBest val_accuracy So Far: 0.5483333468437195\nTotal elapsed time: 00h 16m 36s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(best_hps.get('layers'))\nprint(best_hps.get('lr'))","metadata":{"execution":{"iopub.status.busy":"2022-11-11T09:05:55.191763Z","iopub.execute_input":"2022-11-11T09:05:55.192125Z","iopub.status.idle":"2022-11-11T09:05:55.198203Z","shell.execute_reply.started":"2022-11-11T09:05:55.192095Z","shell.execute_reply":"2022-11-11T09:05:55.197110Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"10\n0.01\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model.trainable = True\nfine_tune_at = 10\n\n    # Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n    \nadam_model_GAN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 0.01),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\n\nfine_tune_epochs = 20\ntotal_epochs =  50 + fine_tune_epochs\n\n\nmodel_checkpoints = [\n    tf.keras.callbacks.ModelCheckpoint(filepath = './hyperparameter_adam_unfrozen_GAN.h5', \n    verbose=1, save_best_only=True, save_weights_only=False, mode='max', monitor='val_accuracy') \n    ]\n\nhistory_fine = adam_model_GAN.fit(train_dataset_GAN,\n                         epochs=total_epochs,\n                         initial_epoch=50,\n                         validation_data=validation_dataset_GAN,\n                             callbacks = [model_checkpoints])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-11T09:07:09.219207Z","iopub.execute_input":"2022-11-11T09:07:09.219604Z","iopub.status.idle":"2022-11-11T09:09:29.475289Z","shell.execute_reply.started":"2022-11-11T09:07:09.219572Z","shell.execute_reply":"2022-11-11T09:09:29.474069Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Epoch 51/70\n44/44 [==============================] - 7s 142ms/step - loss: 5.1829 - accuracy: 0.1750 - val_loss: 3.9045 - val_accuracy: 0.2317\n\nEpoch 00051: val_accuracy improved from -inf to 0.23167, saving model to ./hyperparameter_adam_unfrozen_GAN.h5\nEpoch 52/70\n44/44 [==============================] - 6s 131ms/step - loss: 4.2695 - accuracy: 0.1507 - val_loss: 3.3291 - val_accuracy: 0.2100\n\nEpoch 00052: val_accuracy did not improve from 0.23167\nEpoch 53/70\n44/44 [==============================] - 6s 131ms/step - loss: 4.8210 - accuracy: 0.1400 - val_loss: 2.2985 - val_accuracy: 0.2017\n\nEpoch 00053: val_accuracy did not improve from 0.23167\nEpoch 54/70\n44/44 [==============================] - 6s 129ms/step - loss: 4.0054 - accuracy: 0.1714 - val_loss: 2.8654 - val_accuracy: 0.2117\n\nEpoch 00054: val_accuracy did not improve from 0.23167\nEpoch 55/70\n44/44 [==============================] - 6s 130ms/step - loss: 4.1142 - accuracy: 0.1307 - val_loss: 2.8279 - val_accuracy: 0.1800\n\nEpoch 00055: val_accuracy did not improve from 0.23167\nEpoch 56/70\n44/44 [==============================] - 6s 129ms/step - loss: 4.0276 - accuracy: 0.1364 - val_loss: 2.4432 - val_accuracy: 0.1717\n\nEpoch 00056: val_accuracy did not improve from 0.23167\nEpoch 57/70\n44/44 [==============================] - 6s 129ms/step - loss: 4.3198 - accuracy: 0.1514 - val_loss: 3.1171 - val_accuracy: 0.1450\n\nEpoch 00057: val_accuracy did not improve from 0.23167\nEpoch 58/70\n44/44 [==============================] - 6s 131ms/step - loss: 4.2055 - accuracy: 0.1343 - val_loss: 3.5573 - val_accuracy: 0.1617\n\nEpoch 00058: val_accuracy did not improve from 0.23167\nEpoch 59/70\n44/44 [==============================] - 6s 131ms/step - loss: 4.1893 - accuracy: 0.1300 - val_loss: 2.5298 - val_accuracy: 0.1333\n\nEpoch 00059: val_accuracy did not improve from 0.23167\nEpoch 60/70\n44/44 [==============================] - 6s 129ms/step - loss: 3.9550 - accuracy: 0.1257 - val_loss: 2.7832 - val_accuracy: 0.1300\n\nEpoch 00060: val_accuracy did not improve from 0.23167\nEpoch 61/70\n44/44 [==============================] - 6s 129ms/step - loss: 4.1543 - accuracy: 0.1186 - val_loss: 2.6992 - val_accuracy: 0.1350\n\nEpoch 00061: val_accuracy did not improve from 0.23167\nEpoch 62/70\n44/44 [==============================] - 6s 132ms/step - loss: 4.5715 - accuracy: 0.1214 - val_loss: 2.8291 - val_accuracy: 0.1433\n\nEpoch 00062: val_accuracy did not improve from 0.23167\nEpoch 63/70\n44/44 [==============================] - 6s 129ms/step - loss: 4.1408 - accuracy: 0.1407 - val_loss: 3.3655 - val_accuracy: 0.1333\n\nEpoch 00063: val_accuracy did not improve from 0.23167\nEpoch 64/70\n44/44 [==============================] - 6s 128ms/step - loss: 4.2756 - accuracy: 0.1271 - val_loss: 3.4771 - val_accuracy: 0.1650\n\nEpoch 00064: val_accuracy did not improve from 0.23167\nEpoch 65/70\n44/44 [==============================] - 7s 141ms/step - loss: 4.4445 - accuracy: 0.1186 - val_loss: 2.6146 - val_accuracy: 0.1233\n\nEpoch 00065: val_accuracy did not improve from 0.23167\nEpoch 66/70\n44/44 [==============================] - 6s 128ms/step - loss: 4.2601 - accuracy: 0.1114 - val_loss: 2.8827 - val_accuracy: 0.1433\n\nEpoch 00066: val_accuracy did not improve from 0.23167\nEpoch 67/70\n44/44 [==============================] - 6s 131ms/step - loss: 4.1396 - accuracy: 0.1057 - val_loss: 2.6736 - val_accuracy: 0.1417\n\nEpoch 00067: val_accuracy did not improve from 0.23167\nEpoch 68/70\n44/44 [==============================] - 6s 128ms/step - loss: 5.8370 - accuracy: 0.1357 - val_loss: 3.0289 - val_accuracy: 0.1583\n\nEpoch 00068: val_accuracy did not improve from 0.23167\nEpoch 69/70\n44/44 [==============================] - 6s 135ms/step - loss: 4.1433 - accuracy: 0.1150 - val_loss: 3.1797 - val_accuracy: 0.1383\n\nEpoch 00069: val_accuracy did not improve from 0.23167\nEpoch 70/70\n44/44 [==============================] - 6s 130ms/step - loss: 4.3179 - accuracy: 0.1257 - val_loss: 2.8353 - val_accuracy: 0.1383\n\nEpoch 00070: val_accuracy did not improve from 0.23167\n","output_type":"stream"}]},{"cell_type":"code","source":"adam_model_unfrozen_GAN = tf.keras.models.load_model(\"hyperparameter_adam_unfrozen_GAN.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-11-11T09:10:23.308054Z","iopub.execute_input":"2022-11-11T09:10:23.308653Z","iopub.status.idle":"2022-11-11T09:10:24.135418Z","shell.execute_reply.started":"2022-11-11T09:10:23.308610Z","shell.execute_reply":"2022-11-11T09:10:24.134421Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"adam_model_unfrozen_GAN.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-11-11T09:10:39.916893Z","iopub.execute_input":"2022-11-11T09:10:39.918083Z","iopub.status.idle":"2022-11-11T09:10:43.250577Z","shell.execute_reply.started":"2022-11-11T09:10:39.918036Z","shell.execute_reply":"2022-11-11T09:10:43.249658Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 3s 3s/step - loss: 2.3755 - accuracy: 0.3000\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[2.3754916191101074, 0.30000001192092896]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Transfer Learning and tune the hyperparameters with some unfrozen layers with GAN (SGD optimizer)","metadata":{}},{"cell_type":"code","source":"def model_builder_SGD_unfrozen_GAN(hp):\n    \n    hp_lr = hp.Choice('lr', [1e-2, 1e-3, 1e-4])\n    hp_layers = hp.Choice('layers', [2,4,6,8,10,12,14,16,18,20,22])\n\n    # Fine-tune from this layer onwards\n    fine_tune_at = hp_layers\n\n    # Freeze all the layers before the `fine_tune_at` layer\n    for layer in base_model.layers[:fine_tune_at]:\n      layer.trainable = False\n    \n    sgd_model_GAN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= hp_lr),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\n    return sgd_model_GAN","metadata":{"execution":{"iopub.status.busy":"2022-11-11T09:13:19.629580Z","iopub.execute_input":"2022-11-11T09:13:19.630485Z","iopub.status.idle":"2022-11-11T09:13:19.637934Z","shell.execute_reply.started":"2022-11-11T09:13:19.630439Z","shell.execute_reply":"2022-11-11T09:13:19.636557Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"tuner3 = kt.Hyperband(\n    model_builder_SGD_unfrozen_GAN,\n    objective='val_accuracy',\n    max_epochs=10,\n    directory=\"./\",\n    project_name='vgg_sgd_unfrozen_GAN'\n)\n\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\ntuner3.search(train_dataset_GAN, epochs=50,validation_data=validation_dataset_GAN, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner3.get_best_hyperparameters(num_trials=1)[0]\n\nprint(best_hps.get('layers'))\nprint(best_hps.get('lr'))","metadata":{"execution":{"iopub.status.busy":"2022-11-11T09:20:17.029672Z","iopub.execute_input":"2022-11-11T09:20:17.030032Z","iopub.status.idle":"2022-11-11T09:35:35.392216Z","shell.execute_reply.started":"2022-11-11T09:20:17.030002Z","shell.execute_reply":"2022-11-11T09:35:35.391083Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Trial 30 Complete [00h 01m 18s]\nval_accuracy: 0.3466666638851166\n\nBest val_accuracy So Far: 0.699999988079071\nTotal elapsed time: 00h 15m 18s\n10\n0.001\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model.trainable = True\nfine_tune_at = 10\n\n    # Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n    \nsgd_model_GAN.compile(optimizer=tf.keras.optimizers.SGD(learning_rate= 0.001),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\n\nfine_tune_epochs = 20\ntotal_epochs =  50 + fine_tune_epochs\n\n\nmodel_checkpoints = [\n    tf.keras.callbacks.ModelCheckpoint(filepath = './hyperparameter_sgd_unfrozen_GAN.h5', \n    verbose=1, save_best_only=True, save_weights_only=False, mode='max', monitor='val_accuracy') \n    ]\n\nhistory_fine = sgd_model_GAN.fit(train_dataset_GAN,\n                         epochs=total_epochs,\n                         initial_epoch=50,\n                         validation_data=validation_dataset_GAN,\n                             callbacks = [model_checkpoints])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-11T09:37:50.190355Z","iopub.execute_input":"2022-11-11T09:37:50.191552Z","iopub.status.idle":"2022-11-11T09:40:44.063712Z","shell.execute_reply.started":"2022-11-11T09:37:50.191501Z","shell.execute_reply":"2022-11-11T09:40:44.062460Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 51/70\n44/44 [==============================] - 7s 135ms/step - loss: 3.2408 - accuracy: 0.2643 - val_loss: 2.1152 - val_accuracy: 0.3400\n\nEpoch 00051: val_accuracy improved from -inf to 0.34000, saving model to ./hyperparameter_sgd_unfrozen_GAN.h5\nEpoch 52/70\n44/44 [==============================] - 7s 138ms/step - loss: 3.1409 - accuracy: 0.2786 - val_loss: 2.0712 - val_accuracy: 0.3400\n\nEpoch 00052: val_accuracy did not improve from 0.34000\nEpoch 53/70\n44/44 [==============================] - 6s 132ms/step - loss: 2.9683 - accuracy: 0.2857 - val_loss: 2.0654 - val_accuracy: 0.3700\n\nEpoch 00053: val_accuracy improved from 0.34000 to 0.37000, saving model to ./hyperparameter_sgd_unfrozen_GAN.h5\nEpoch 54/70\n44/44 [==============================] - 6s 129ms/step - loss: 2.8573 - accuracy: 0.2829 - val_loss: 2.0299 - val_accuracy: 0.3483\n\nEpoch 00054: val_accuracy did not improve from 0.37000\nEpoch 55/70\n44/44 [==============================] - 6s 131ms/step - loss: 2.8026 - accuracy: 0.2864 - val_loss: 2.0675 - val_accuracy: 0.3383\n\nEpoch 00055: val_accuracy did not improve from 0.37000\nEpoch 56/70\n44/44 [==============================] - 6s 140ms/step - loss: 2.7452 - accuracy: 0.2764 - val_loss: 1.9994 - val_accuracy: 0.3383\n\nEpoch 00056: val_accuracy did not improve from 0.37000\nEpoch 57/70\n44/44 [==============================] - 6s 130ms/step - loss: 2.7308 - accuracy: 0.2964 - val_loss: 2.0019 - val_accuracy: 0.3417\n\nEpoch 00057: val_accuracy did not improve from 0.37000\nEpoch 58/70\n44/44 [==============================] - 6s 130ms/step - loss: 2.8060 - accuracy: 0.2993 - val_loss: 1.9916 - val_accuracy: 0.3383\n\nEpoch 00058: val_accuracy did not improve from 0.37000\nEpoch 59/70\n44/44 [==============================] - 6s 131ms/step - loss: 2.6545 - accuracy: 0.2957 - val_loss: 1.9786 - val_accuracy: 0.3467\n\nEpoch 00059: val_accuracy did not improve from 0.37000\nEpoch 60/70\n44/44 [==============================] - 6s 129ms/step - loss: 2.6570 - accuracy: 0.2707 - val_loss: 1.9828 - val_accuracy: 0.3383\n\nEpoch 00060: val_accuracy did not improve from 0.37000\nEpoch 61/70\n44/44 [==============================] - 6s 132ms/step - loss: 3.0698 - accuracy: 0.2757 - val_loss: 2.0207 - val_accuracy: 0.3467\n\nEpoch 00061: val_accuracy did not improve from 0.37000\nEpoch 62/70\n44/44 [==============================] - 7s 152ms/step - loss: 2.5949 - accuracy: 0.2729 - val_loss: 2.0243 - val_accuracy: 0.3467\n\nEpoch 00062: val_accuracy did not improve from 0.37000\nEpoch 63/70\n44/44 [==============================] - 6s 136ms/step - loss: 2.6565 - accuracy: 0.2971 - val_loss: 2.0404 - val_accuracy: 0.3383\n\nEpoch 00063: val_accuracy did not improve from 0.37000\nEpoch 64/70\n44/44 [==============================] - 6s 130ms/step - loss: 2.7197 - accuracy: 0.2921 - val_loss: 2.0178 - val_accuracy: 0.3383\n\nEpoch 00064: val_accuracy did not improve from 0.37000\nEpoch 65/70\n44/44 [==============================] - 6s 131ms/step - loss: 2.7539 - accuracy: 0.2857 - val_loss: 2.0008 - val_accuracy: 0.3383\n\nEpoch 00065: val_accuracy did not improve from 0.37000\nEpoch 66/70\n44/44 [==============================] - 6s 131ms/step - loss: 2.5998 - accuracy: 0.2800 - val_loss: 2.0107 - val_accuracy: 0.3383\n\nEpoch 00066: val_accuracy did not improve from 0.37000\nEpoch 67/70\n44/44 [==============================] - 6s 134ms/step - loss: 2.9463 - accuracy: 0.2871 - val_loss: 1.9563 - val_accuracy: 0.3400\n\nEpoch 00067: val_accuracy did not improve from 0.37000\nEpoch 68/70\n44/44 [==============================] - 6s 135ms/step - loss: 2.7161 - accuracy: 0.2671 - val_loss: 1.9480 - val_accuracy: 0.3483\n\nEpoch 00068: val_accuracy did not improve from 0.37000\nEpoch 69/70\n44/44 [==============================] - 6s 137ms/step - loss: 2.7334 - accuracy: 0.2757 - val_loss: 1.9364 - val_accuracy: 0.3400\n\nEpoch 00069: val_accuracy did not improve from 0.37000\nEpoch 70/70\n44/44 [==============================] - 6s 131ms/step - loss: 3.1990 - accuracy: 0.2750 - val_loss: 2.3186 - val_accuracy: 0.3383\n\nEpoch 00070: val_accuracy did not improve from 0.37000\n","output_type":"stream"}]},{"cell_type":"code","source":"sgd_model_unfrozen_GAN = tf.keras.models.load_model(\"hyperparameter_sgd_unfrozen_GAN.h5\")\nsgd_model_unfrozen_GAN.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-11-11T09:41:16.838482Z","iopub.execute_input":"2022-11-11T09:41:16.839140Z","iopub.status.idle":"2022-11-11T09:41:22.729092Z","shell.execute_reply.started":"2022-11-11T09:41:16.839104Z","shell.execute_reply":"2022-11-11T09:41:22.727934Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 3s 3s/step - loss: 5.0617 - accuracy: 0.3000\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"[5.061696529388428, 0.30000001192092896]"},"metadata":{}}]}]}